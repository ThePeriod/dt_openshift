apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-05-04T21:36:10Z"
    generateName: machine-approver-d54df7b84-
    labels:
      app: machine-approver
      pod-template-hash: d54df7b84
    name: machine-approver-d54df7b84-5wxxd
    namespace: openshift-cluster-machine-approver
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: machine-approver-d54df7b84
      uid: 349e313a-0efd-4b77-9568-c08818a55f75
    resourceVersion: "114617510"
    uid: 51afc36b-b56c-4d72-9e23-86c752cb780d
  spec:
    containers:
    - args:
      - --secure-listen-address=0.0.0.0:9192
      - --upstream=http://127.0.0.1:9191/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --config-file=/etc/kube-rbac-proxy/config-file.yaml
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
      - --logtostderr=true
      - --v=3
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9192
        hostPort: 9192
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kube-rbac-proxy
        name: auth-proxy-config
      - mountPath: /etc/tls/private
        name: machine-approver-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rzpf4
        readOnly: true
    - args:
      - --config=/var/run/configmaps/config/config.yaml
      - -v=2
      - --logtostderr
      - --leader-elect=true
      - --leader-elect-lease-duration=137s
      - --leader-elect-renew-deadline=107s
      - --leader-elect-retry-period=26s
      - --leader-elect-resource-namespace=openshift-cluster-machine-approver
      command:
      - /usr/bin/machine-approver
      env:
      - name: RELEASE_VERSION
        value: 4.10.53
      - name: METRICS_PORT
        value: "9191"
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1f036fd712d80120901f56b2b06c3f1bf942ad79e7cfee89e67b398f57e86c37
      imagePullPolicy: IfNotPresent
      name: machine-approver-controller
      resources:
        requests:
          cpu: 10m
          memory: 50Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /var/run/configmaps/config
        name: config
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rzpf4
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ocp4azu-sj2sl-master-1
    nodeSelector:
      node-role.kubernetes.io/master: ""
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: machine-approver-sa
    serviceAccountName: machine-approver-sa
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 120
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 120
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-rbac-proxy
      name: auth-proxy-config
    - name: machine-approver-tls
      secret:
        defaultMode: 420
        secretName: machine-approver-tls
    - configMap:
        defaultMode: 440
        name: machine-approver-config
        optional: true
      name: config
    - name: kube-api-access-rzpf4
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-05-04T21:40:05Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-05-11T18:26:24Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-05-11T18:26:24Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-05-04T21:40:05Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://20eec10fd143310f2117697c84c7171c2e3553fe47a17d95482a006fa7879474
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2023-05-11T18:26:19Z"
    - containerID: cri-o://7dd3d1cdb87997517b028c51075d1b6a755f1c6a724b9e0c33bb5a2b3abfa97e
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1f036fd712d80120901f56b2b06c3f1bf942ad79e7cfee89e67b398f57e86c37
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:1f036fd712d80120901f56b2b06c3f1bf942ad79e7cfee89e67b398f57e86c37
      lastState:
        terminated:
          containerID: cri-o://bf545ea6f7219fc440b4dbb3166ded06757f56a5b6e00c60cf8b44c73117e80f
          exitCode: 255
          finishedAt: "2023-05-11T18:26:23Z"
          message: " might not work.\nW0511 18:26:20.966530       1 client_config.go:617]
            Neither --kubeconfig nor --master was specified.  Using the inClusterConfig.
            \ This might not work.\nF0511 18:26:23.305925       1 main.go:102] Can't
            create clients: failed to create client: Get \"https://172.30.0.1:443/api?timeout=32s\":
            dial tcp 172.30.0.1:443: connect: no route to host\ngoroutine 1 [running]:\nk8s.io/klog/v2.stacks(0x1)\n\t/go/src/github.com/openshift/cluster-machine-approver/vendor/k8s.io/klog/v2/klog.go:1038
            +0x8a\nk8s.io/klog/v2.(*loggingT).output(0x2ba73c0, 0x3, 0x0, 0xc000363180,
            0x0, {0x215ea51, 0x1}, 0xc0003b8230, 0x0)\n\t/go/src/github.com/openshift/cluster-machine-approver/vendor/k8s.io/klog/v2/klog.go:987
            +0x5fd\nk8s.io/klog/v2.(*loggingT).printf(0x0, 0x1, 0x0, {0x0, 0x0}, {0x1a74c27,
            0x18}, {0xc0003b8230, 0x1, 0x1})\n\t/go/src/github.com/openshift/cluster-machine-approver/vendor/k8s.io/klog/v2/klog.go:753
            +0x1c5\nk8s.io/klog/v2.Fatalf(...)\n\t/go/src/github.com/openshift/cluster-machine-approver/vendor/k8s.io/klog/v2/klog.go:1532\nmain.main()\n\t/go/src/github.com/openshift/cluster-machine-approver/main.go:102
            +0xb45\n\ngoroutine 6 [chan receive]:\nk8s.io/klog/v2.(*loggingT).flushDaemon(0x0)\n\t/go/src/github.com/openshift/cluster-machine-approver/vendor/k8s.io/klog/v2/klog.go:1181
            +0x6a\ncreated by k8s.io/klog/v2.init.0\n\t/go/src/github.com/openshift/cluster-machine-approver/vendor/k8s.io/klog/v2/klog.go:420
            +0xfb\n\ngoroutine 18 [sleep]:\ntime.Sleep(0x6fc23ac00)\n\t/usr/lib/golang/src/runtime/time.go:193
            +0x12e\nsigs.k8s.io/controller-runtime/pkg/log.init.0.func1()\n\t/go/src/github.com/openshift/cluster-machine-approver/vendor/sigs.k8s.io/controller-runtime/pkg/log/log.go:63
            +0x38\ncreated by sigs.k8s.io/controller-runtime/pkg/log.init.0\n\t/go/src/github.com/openshift/cluster-machine-approver/vendor/sigs.k8s.io/controller-runtime/pkg/log/log.go:62
            +0x25\n\ngoroutine 28 [runnable]:\nnet/http.setRequestCancel.func4()\n\t/usr/lib/golang/src/net/http/client.go:398
            +0x94\ncreated by net/http.setRequestCancel\n\t/usr/lib/golang/src/net/http/client.go:397
            +0x43e\n"
          reason: Error
          startedAt: "2023-05-11T18:26:19Z"
      name: machine-approver-controller
      ready: true
      restartCount: 6
      started: true
      state:
        running:
          startedAt: "2023-05-11T18:26:24Z"
    hostIP: 10.80.80.8
    phase: Running
    podIP: 10.80.80.8
    podIPs:
    - ip: 10.80.80.8
    qosClass: Burstable
    startTime: "2023-05-04T21:40:05Z"
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
