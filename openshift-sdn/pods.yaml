apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-05-25T14:39:41Z"
    generateName: sdn-
    labels:
      app: sdn
      component: network
      controller-revision-hash: 749f49c4cc
      openshift.io/component: network
      pod-template-generation: "1"
      type: infra
    name: sdn-2v9qz
    namespace: openshift-sdn
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sdn
      uid: 79c4ac3b-dde1-4470-a005-a221cb9e48d9
    resourceVersion: "476624944"
    uid: ed7e6abd-db0b-4d25-bb00-5467636da787
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ocp4azu-sj2sl-worker-noprod-dev-brazilsouth1-vlxcp
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail

        # if another process is listening on the cni-server socket, wait until it exits
        trap 'kill $(jobs -p); rm -f /etc/cni/net.d/80-openshift-network.conf ; exit 0' TERM
        retries=0
        while true; do
          if echo 'test' | socat - UNIX-CONNECT:/var/run/openshift-sdn/cniserver/socket &>/dev/null; then
            echo "warning: Another process is currently listening on the CNI socket, waiting 15s ..." 2>&1
            sleep 15 & wait
            (( retries += 1 ))
          else
            break
          fi
          if [[ "${retries}" -gt 40 ]]; then
            echo "error: Another process is currently listening on the CNI socket, exiting" 2>&1
            exit 1
          fi
        done

        # local environment overrides
        if [[ -f /etc/sysconfig/openshift-sdn ]]; then
          set -o allexport
          source /etc/sysconfig/openshift-sdn
          set +o allexport
        fi
        #BUG: cdc accidentally mounted /etc/sysconfig/openshift-sdn as DirectoryOrCreate; clean it up so we can ultimately mount /etc/sysconfig/openshift-sdn as FileOrCreate
        # Once this is released, then we can mount it properly
        if [[ -d /etc/sysconfig/openshift-sdn ]]; then
          rmdir /etc/sysconfig/openshift-sdn || true
        fi

        # configmap-based overrides
        if [[ -f /env/${K8S_NODE_NAME} ]]; then
          set -o allexport
          source /env/${K8S_NODE_NAME}
          set +o allexport
        fi

        # Take over network functions on the node
        rm -f /etc/cni/net.d/80-openshift-network.conf
        cp -f /opt/cni/bin/openshift-sdn /host-cni-bin/

        mtu_override_flag=
        if [[ -f /config/mtu.yaml ]]; then
          mtu_override_flag="--mtu-override /config/mtu.yaml"
        fi

        # Launch the network process
        exec /usr/bin/openshift-sdn-node \
          --node-name ${K8S_NODE_NAME} --node-ip ${K8S_NODE_IP} \
          --platform-type Azure \
          --proxy-config /config/kube-proxy-config.yaml \
          ${mtu_override_flag} \
          --v ${OPENSHIFT_SDN_LOG_LEVEL:-2}
      env:
      - name: KUBERNETES_SERVICE_PORT
        value: "6443"
      - name: KUBERNETES_SERVICE_HOST
        value: api-int.ocp4azu.dirtrab.cl
      - name: OPENSHIFT_DNS_DOMAIN
        value: cluster.local
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: K8S_NODE_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - rm
            - -f
            - /etc/cni/net.d/80-openshift-network.conf
            - /host-cni-bin/openshift-sdn
      name: sdn
      ports:
      - containerPort: 10256
        hostPort: 10256
        name: healthz
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - test
          - -f
          - /etc/cni/net.d/80-openshift-network.conf
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /config
        name: config
        readOnly: true
      - mountPath: /env
        name: env-overrides
      - mountPath: /var/run
        name: host-var-run
      - mountPath: /var/run/dbus/
        name: host-var-run-dbus
        readOnly: true
      - mountPath: /var/run/openvswitch/
        name: host-var-run-ovs
        readOnly: true
      - mountPath: /var/run/kubernetes/
        name: host-var-run-kubernetes
        readOnly: true
      - mountPath: /run/netns
        mountPropagation: HostToContainer
        name: host-run-netns
        readOnly: true
      - mountPath: /host/var/run/netns
        mountPropagation: HostToContainer
        name: host-var-run-netns
        readOnly: true
      - mountPath: /var/run/openshift-sdn
        name: host-var-run-openshift-sdn
      - mountPath: /host
        mountPropagation: HostToContainer
        name: host-slash
        readOnly: true
      - mountPath: /host-cni-bin
        name: host-cni-bin
      - mountPath: /etc/cni/net.d
        name: host-cni-conf
      - mountPath: /var/lib/cni/networks/openshift-sdn
        name: host-var-lib-cni-networks-openshift-sdn
      - mountPath: /lib/modules
        name: host-modules
        readOnly: true
      - mountPath: /etc/sysconfig
        name: etc-sysconfig
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-kkbjt
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail
        TLS_PK=/etc/pki/tls/metrics-certs/tls.key
        TLS_CERT=/etc/pki/tls/metrics-certs/tls.crt

        # As the secret mount is optional we must wait for the files to be present.
        # The service is created in monitor.yaml and this is created in sdn.yaml.
        # If it isn't created there is probably an issue so we want to crashloop.
        TS=$(date +%s)
        WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
        HAS_LOGGED_INFO=0

        log_missing_certs(){
            CUR_TS=$(date +%s)
            if [[ "${CUR_TS}" -gt "WARN_TS"  ]]; then
              echo $(date -Iseconds) WARN: sdn-metrics-certs not mounted after 20 minutes.
            elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
              echo $(date -Iseconds) INFO: sdn-metrics-certs not mounted. Waiting 20 minutes.
              HAS_LOGGED_INFO=1
            fi
        }

        while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
          log_missing_certs
          sleep 5
        done

        echo $(date -Iseconds) INFO: sdn-metrics-certs mounted, starting kube-rbac-proxy
        exec /usr/bin/kube-rbac-proxy \
          --logtostderr \
          --secure-listen-address=:9101 \
          --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
          --upstream=http://127.0.0.1:29101/ \
          --tls-private-key-file=${TLS_PK} \
          --tls-cert-file=${TLS_CERT}
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9101
        hostPort: 9101
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/tls/metrics-certs
        name: sdn-metrics-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-kkbjt
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        set -xe

        touch /var/run/add_iptables.sh
        chmod 0755 /var/run/add_iptables.sh
        cat <<'EOF' > /var/run/add_iptables.sh
        #!/bin/sh
        if [ -z "$3" ]
        then
             echo "Called with host address missing, ignore"
             exit 0
        fi
        echo "Adding ICMP drop rule for '$3' "
        if iptables -C AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        then
             echo "iptables already set for $3"
        else
             iptables -A AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        fi
        EOF

        echo "I$(date "+%m%d %H:%M:%S.%N") - drop-icmp - start drop-icmp ${K8S_NODE}"
        iptables -X AZURE_CHECK_ICMP_SOURCE || true
        iptables -N AZURE_CHECK_ICMP_SOURCE || true
        iptables -F AZURE_CHECK_ICMP_SOURCE
        iptables -D INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE || true
        iptables -I INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE
        iptables -N AZURE_ICMP_ACTION || true
        iptables -F AZURE_ICMP_ACTION
        iptables -A AZURE_ICMP_ACTION -j LOG
        iptables -A AZURE_ICMP_ACTION -j DROP
        /host/usr/bin/oc observe pods -n openshift-sdn -l app=sdn -a '{ .status.hostIP }' -- /var/run/add_iptables.sh
      env:
      - name: K8S_NODE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/bash
            - -c
            - echo drop-icmp done
      name: drop-icmp
      resources:
        requests:
          cpu: 5m
          memory: 20Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        name: host-slash
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-kkbjt
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: sdn-dockercfg-46nvg
    nodeName: ocp4azu-sj2sl-worker-noprod-dev-brazilsouth1-vlxcp
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: sdn
    serviceAccountName: sdn
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sdn-config
      name: config
    - configMap:
        defaultMode: 420
        name: env-overrides
        optional: true
      name: env-overrides
    - hostPath:
        path: /etc/sysconfig
        type: ""
      name: etc-sysconfig
    - hostPath:
        path: /lib/modules
        type: ""
      name: host-modules
    - hostPath:
        path: /var/run
        type: ""
      name: host-var-run
    - hostPath:
        path: /run/netns
        type: ""
      name: host-run-netns
    - hostPath:
        path: /var/run/netns
        type: ""
      name: host-var-run-netns
    - hostPath:
        path: /var/run/dbus
        type: ""
      name: host-var-run-dbus
    - hostPath:
        path: /var/run/openvswitch
        type: ""
      name: host-var-run-ovs
    - hostPath:
        path: /var/run/kubernetes
        type: ""
      name: host-var-run-kubernetes
    - hostPath:
        path: /var/run/openshift-sdn
        type: ""
      name: host-var-run-openshift-sdn
    - hostPath:
        path: /
        type: ""
      name: host-slash
    - hostPath:
        path: /var/lib/cni/bin
        type: ""
      name: host-cni-bin
    - hostPath:
        path: /var/run/multus/cni/net.d
        type: ""
      name: host-cni-conf
    - hostPath:
        path: /var/lib/cni/networks/openshift-sdn
        type: ""
      name: host-var-lib-cni-networks-openshift-sdn
    - name: sdn-metrics-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: sdn-metrics-certs
    - name: kube-api-access-kkbjt
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T14:39:42Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T14:40:08Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T14:40:08Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T14:39:41Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://da51d16d0a30b3226df95e2b8ffc83264c01a851eb57a77370ae6d26dd450267
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: drop-icmp
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T14:40:07Z"
    - containerID: cri-o://671ccc240c8701a8d914a203cc1ec136472c2599ed19d9375ba6c267650dafd5
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T14:40:07Z"
    - containerID: cri-o://304780249e48783411ba348efa06612df6671faeb3f2ccc92459786275e67d81
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: sdn
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T14:40:02Z"
    hostIP: 10.80.80.5
    phase: Running
    podIP: 10.80.80.5
    podIPs:
    - ip: 10.80.80.5
    qosClass: Burstable
    startTime: "2023-05-25T14:39:42Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-05-25T13:39:03Z"
    generateName: sdn-
    labels:
      app: sdn
      component: network
      controller-revision-hash: 749f49c4cc
      openshift.io/component: network
      pod-template-generation: "1"
      type: infra
    name: sdn-5p4fn
    namespace: openshift-sdn
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sdn
      uid: 79c4ac3b-dde1-4470-a005-a221cb9e48d9
    resourceVersion: "491646517"
    uid: e4083032-f3ba-4365-a0a4-b4b593f9ca0b
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ocp4azu-sj2sl-worker-prod-brazilsouth1-lks8v
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail

        # if another process is listening on the cni-server socket, wait until it exits
        trap 'kill $(jobs -p); rm -f /etc/cni/net.d/80-openshift-network.conf ; exit 0' TERM
        retries=0
        while true; do
          if echo 'test' | socat - UNIX-CONNECT:/var/run/openshift-sdn/cniserver/socket &>/dev/null; then
            echo "warning: Another process is currently listening on the CNI socket, waiting 15s ..." 2>&1
            sleep 15 & wait
            (( retries += 1 ))
          else
            break
          fi
          if [[ "${retries}" -gt 40 ]]; then
            echo "error: Another process is currently listening on the CNI socket, exiting" 2>&1
            exit 1
          fi
        done

        # local environment overrides
        if [[ -f /etc/sysconfig/openshift-sdn ]]; then
          set -o allexport
          source /etc/sysconfig/openshift-sdn
          set +o allexport
        fi
        #BUG: cdc accidentally mounted /etc/sysconfig/openshift-sdn as DirectoryOrCreate; clean it up so we can ultimately mount /etc/sysconfig/openshift-sdn as FileOrCreate
        # Once this is released, then we can mount it properly
        if [[ -d /etc/sysconfig/openshift-sdn ]]; then
          rmdir /etc/sysconfig/openshift-sdn || true
        fi

        # configmap-based overrides
        if [[ -f /env/${K8S_NODE_NAME} ]]; then
          set -o allexport
          source /env/${K8S_NODE_NAME}
          set +o allexport
        fi

        # Take over network functions on the node
        rm -f /etc/cni/net.d/80-openshift-network.conf
        cp -f /opt/cni/bin/openshift-sdn /host-cni-bin/

        mtu_override_flag=
        if [[ -f /config/mtu.yaml ]]; then
          mtu_override_flag="--mtu-override /config/mtu.yaml"
        fi

        # Launch the network process
        exec /usr/bin/openshift-sdn-node \
          --node-name ${K8S_NODE_NAME} --node-ip ${K8S_NODE_IP} \
          --platform-type Azure \
          --proxy-config /config/kube-proxy-config.yaml \
          ${mtu_override_flag} \
          --v ${OPENSHIFT_SDN_LOG_LEVEL:-2}
      env:
      - name: KUBERNETES_SERVICE_PORT
        value: "6443"
      - name: KUBERNETES_SERVICE_HOST
        value: api-int.ocp4azu.dirtrab.cl
      - name: OPENSHIFT_DNS_DOMAIN
        value: cluster.local
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: K8S_NODE_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - rm
            - -f
            - /etc/cni/net.d/80-openshift-network.conf
            - /host-cni-bin/openshift-sdn
      name: sdn
      ports:
      - containerPort: 10256
        hostPort: 10256
        name: healthz
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - test
          - -f
          - /etc/cni/net.d/80-openshift-network.conf
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /config
        name: config
        readOnly: true
      - mountPath: /env
        name: env-overrides
      - mountPath: /var/run
        name: host-var-run
      - mountPath: /var/run/dbus/
        name: host-var-run-dbus
        readOnly: true
      - mountPath: /var/run/openvswitch/
        name: host-var-run-ovs
        readOnly: true
      - mountPath: /var/run/kubernetes/
        name: host-var-run-kubernetes
        readOnly: true
      - mountPath: /run/netns
        mountPropagation: HostToContainer
        name: host-run-netns
        readOnly: true
      - mountPath: /host/var/run/netns
        mountPropagation: HostToContainer
        name: host-var-run-netns
        readOnly: true
      - mountPath: /var/run/openshift-sdn
        name: host-var-run-openshift-sdn
      - mountPath: /host
        mountPropagation: HostToContainer
        name: host-slash
        readOnly: true
      - mountPath: /host-cni-bin
        name: host-cni-bin
      - mountPath: /etc/cni/net.d
        name: host-cni-conf
      - mountPath: /var/lib/cni/networks/openshift-sdn
        name: host-var-lib-cni-networks-openshift-sdn
      - mountPath: /lib/modules
        name: host-modules
        readOnly: true
      - mountPath: /etc/sysconfig
        name: etc-sysconfig
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zqtqs
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail
        TLS_PK=/etc/pki/tls/metrics-certs/tls.key
        TLS_CERT=/etc/pki/tls/metrics-certs/tls.crt

        # As the secret mount is optional we must wait for the files to be present.
        # The service is created in monitor.yaml and this is created in sdn.yaml.
        # If it isn't created there is probably an issue so we want to crashloop.
        TS=$(date +%s)
        WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
        HAS_LOGGED_INFO=0

        log_missing_certs(){
            CUR_TS=$(date +%s)
            if [[ "${CUR_TS}" -gt "WARN_TS"  ]]; then
              echo $(date -Iseconds) WARN: sdn-metrics-certs not mounted after 20 minutes.
            elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
              echo $(date -Iseconds) INFO: sdn-metrics-certs not mounted. Waiting 20 minutes.
              HAS_LOGGED_INFO=1
            fi
        }

        while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
          log_missing_certs
          sleep 5
        done

        echo $(date -Iseconds) INFO: sdn-metrics-certs mounted, starting kube-rbac-proxy
        exec /usr/bin/kube-rbac-proxy \
          --logtostderr \
          --secure-listen-address=:9101 \
          --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
          --upstream=http://127.0.0.1:29101/ \
          --tls-private-key-file=${TLS_PK} \
          --tls-cert-file=${TLS_CERT}
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9101
        hostPort: 9101
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/tls/metrics-certs
        name: sdn-metrics-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zqtqs
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        set -xe

        touch /var/run/add_iptables.sh
        chmod 0755 /var/run/add_iptables.sh
        cat <<'EOF' > /var/run/add_iptables.sh
        #!/bin/sh
        if [ -z "$3" ]
        then
             echo "Called with host address missing, ignore"
             exit 0
        fi
        echo "Adding ICMP drop rule for '$3' "
        if iptables -C AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        then
             echo "iptables already set for $3"
        else
             iptables -A AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        fi
        EOF

        echo "I$(date "+%m%d %H:%M:%S.%N") - drop-icmp - start drop-icmp ${K8S_NODE}"
        iptables -X AZURE_CHECK_ICMP_SOURCE || true
        iptables -N AZURE_CHECK_ICMP_SOURCE || true
        iptables -F AZURE_CHECK_ICMP_SOURCE
        iptables -D INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE || true
        iptables -I INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE
        iptables -N AZURE_ICMP_ACTION || true
        iptables -F AZURE_ICMP_ACTION
        iptables -A AZURE_ICMP_ACTION -j LOG
        iptables -A AZURE_ICMP_ACTION -j DROP
        /host/usr/bin/oc observe pods -n openshift-sdn -l app=sdn -a '{ .status.hostIP }' -- /var/run/add_iptables.sh
      env:
      - name: K8S_NODE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/bash
            - -c
            - echo drop-icmp done
      name: drop-icmp
      resources:
        requests:
          cpu: 5m
          memory: 20Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        name: host-slash
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zqtqs
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: sdn-dockercfg-46nvg
    nodeName: ocp4azu-sj2sl-worker-prod-brazilsouth1-lks8v
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: sdn
    serviceAccountName: sdn
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sdn-config
      name: config
    - configMap:
        defaultMode: 420
        name: env-overrides
        optional: true
      name: env-overrides
    - hostPath:
        path: /etc/sysconfig
        type: ""
      name: etc-sysconfig
    - hostPath:
        path: /lib/modules
        type: ""
      name: host-modules
    - hostPath:
        path: /var/run
        type: ""
      name: host-var-run
    - hostPath:
        path: /run/netns
        type: ""
      name: host-run-netns
    - hostPath:
        path: /var/run/netns
        type: ""
      name: host-var-run-netns
    - hostPath:
        path: /var/run/dbus
        type: ""
      name: host-var-run-dbus
    - hostPath:
        path: /var/run/openvswitch
        type: ""
      name: host-var-run-ovs
    - hostPath:
        path: /var/run/kubernetes
        type: ""
      name: host-var-run-kubernetes
    - hostPath:
        path: /var/run/openshift-sdn
        type: ""
      name: host-var-run-openshift-sdn
    - hostPath:
        path: /
        type: ""
      name: host-slash
    - hostPath:
        path: /var/lib/cni/bin
        type: ""
      name: host-cni-bin
    - hostPath:
        path: /var/run/multus/cni/net.d
        type: ""
      name: host-cni-conf
    - hostPath:
        path: /var/lib/cni/networks/openshift-sdn
        type: ""
      name: host-var-lib-cni-networks-openshift-sdn
    - name: sdn-metrics-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: sdn-metrics-certs
    - name: kube-api-access-zqtqs
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T13:39:04Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T13:39:30Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T13:39:30Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T13:39:03Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://06d98fa6e8e0be57878cb148c52bac78b8f5df1cf9396e4b7b10956871f47539
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: drop-icmp
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T13:39:30Z"
    - containerID: cri-o://00cacedbd1de251ae652db4ed6f34f750d4900d2109208605448ee75b2ccf98c
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T13:39:29Z"
    - containerID: cri-o://ffda7ed8cd7c53f25ac8ae331225db95e73dbace8dd76aa91ee9d381662a9478
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: sdn
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T13:39:24Z"
    hostIP: 10.80.80.19
    phase: Running
    podIP: 10.80.80.19
    podIPs:
    - ip: 10.80.80.19
    qosClass: Burstable
    startTime: "2023-05-25T13:39:04Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-05-25T19:26:47Z"
    generateName: sdn-
    labels:
      app: sdn
      component: network
      controller-revision-hash: 749f49c4cc
      openshift.io/component: network
      pod-template-generation: "1"
      type: infra
    name: sdn-7vqkv
    namespace: openshift-sdn
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sdn
      uid: 79c4ac3b-dde1-4470-a005-a221cb9e48d9
    resourceVersion: "380476347"
    uid: bfa2e391-de30-4f4a-bfdc-df9f25271459
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ocp4azu-sj2sl-worker-prod-brazilsouth1-mjsb5
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail

        # if another process is listening on the cni-server socket, wait until it exits
        trap 'kill $(jobs -p); rm -f /etc/cni/net.d/80-openshift-network.conf ; exit 0' TERM
        retries=0
        while true; do
          if echo 'test' | socat - UNIX-CONNECT:/var/run/openshift-sdn/cniserver/socket &>/dev/null; then
            echo "warning: Another process is currently listening on the CNI socket, waiting 15s ..." 2>&1
            sleep 15 & wait
            (( retries += 1 ))
          else
            break
          fi
          if [[ "${retries}" -gt 40 ]]; then
            echo "error: Another process is currently listening on the CNI socket, exiting" 2>&1
            exit 1
          fi
        done

        # local environment overrides
        if [[ -f /etc/sysconfig/openshift-sdn ]]; then
          set -o allexport
          source /etc/sysconfig/openshift-sdn
          set +o allexport
        fi
        #BUG: cdc accidentally mounted /etc/sysconfig/openshift-sdn as DirectoryOrCreate; clean it up so we can ultimately mount /etc/sysconfig/openshift-sdn as FileOrCreate
        # Once this is released, then we can mount it properly
        if [[ -d /etc/sysconfig/openshift-sdn ]]; then
          rmdir /etc/sysconfig/openshift-sdn || true
        fi

        # configmap-based overrides
        if [[ -f /env/${K8S_NODE_NAME} ]]; then
          set -o allexport
          source /env/${K8S_NODE_NAME}
          set +o allexport
        fi

        # Take over network functions on the node
        rm -f /etc/cni/net.d/80-openshift-network.conf
        cp -f /opt/cni/bin/openshift-sdn /host-cni-bin/

        mtu_override_flag=
        if [[ -f /config/mtu.yaml ]]; then
          mtu_override_flag="--mtu-override /config/mtu.yaml"
        fi

        # Launch the network process
        exec /usr/bin/openshift-sdn-node \
          --node-name ${K8S_NODE_NAME} --node-ip ${K8S_NODE_IP} \
          --platform-type Azure \
          --proxy-config /config/kube-proxy-config.yaml \
          ${mtu_override_flag} \
          --v ${OPENSHIFT_SDN_LOG_LEVEL:-2}
      env:
      - name: KUBERNETES_SERVICE_PORT
        value: "6443"
      - name: KUBERNETES_SERVICE_HOST
        value: api-int.ocp4azu.dirtrab.cl
      - name: OPENSHIFT_DNS_DOMAIN
        value: cluster.local
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: K8S_NODE_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - rm
            - -f
            - /etc/cni/net.d/80-openshift-network.conf
            - /host-cni-bin/openshift-sdn
      name: sdn
      ports:
      - containerPort: 10256
        hostPort: 10256
        name: healthz
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - test
          - -f
          - /etc/cni/net.d/80-openshift-network.conf
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /config
        name: config
        readOnly: true
      - mountPath: /env
        name: env-overrides
      - mountPath: /var/run
        name: host-var-run
      - mountPath: /var/run/dbus/
        name: host-var-run-dbus
        readOnly: true
      - mountPath: /var/run/openvswitch/
        name: host-var-run-ovs
        readOnly: true
      - mountPath: /var/run/kubernetes/
        name: host-var-run-kubernetes
        readOnly: true
      - mountPath: /run/netns
        mountPropagation: HostToContainer
        name: host-run-netns
        readOnly: true
      - mountPath: /host/var/run/netns
        mountPropagation: HostToContainer
        name: host-var-run-netns
        readOnly: true
      - mountPath: /var/run/openshift-sdn
        name: host-var-run-openshift-sdn
      - mountPath: /host
        mountPropagation: HostToContainer
        name: host-slash
        readOnly: true
      - mountPath: /host-cni-bin
        name: host-cni-bin
      - mountPath: /etc/cni/net.d
        name: host-cni-conf
      - mountPath: /var/lib/cni/networks/openshift-sdn
        name: host-var-lib-cni-networks-openshift-sdn
      - mountPath: /lib/modules
        name: host-modules
        readOnly: true
      - mountPath: /etc/sysconfig
        name: etc-sysconfig
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zgd9q
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail
        TLS_PK=/etc/pki/tls/metrics-certs/tls.key
        TLS_CERT=/etc/pki/tls/metrics-certs/tls.crt

        # As the secret mount is optional we must wait for the files to be present.
        # The service is created in monitor.yaml and this is created in sdn.yaml.
        # If it isn't created there is probably an issue so we want to crashloop.
        TS=$(date +%s)
        WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
        HAS_LOGGED_INFO=0

        log_missing_certs(){
            CUR_TS=$(date +%s)
            if [[ "${CUR_TS}" -gt "WARN_TS"  ]]; then
              echo $(date -Iseconds) WARN: sdn-metrics-certs not mounted after 20 minutes.
            elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
              echo $(date -Iseconds) INFO: sdn-metrics-certs not mounted. Waiting 20 minutes.
              HAS_LOGGED_INFO=1
            fi
        }

        while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
          log_missing_certs
          sleep 5
        done

        echo $(date -Iseconds) INFO: sdn-metrics-certs mounted, starting kube-rbac-proxy
        exec /usr/bin/kube-rbac-proxy \
          --logtostderr \
          --secure-listen-address=:9101 \
          --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
          --upstream=http://127.0.0.1:29101/ \
          --tls-private-key-file=${TLS_PK} \
          --tls-cert-file=${TLS_CERT}
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9101
        hostPort: 9101
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/tls/metrics-certs
        name: sdn-metrics-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zgd9q
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        set -xe

        touch /var/run/add_iptables.sh
        chmod 0755 /var/run/add_iptables.sh
        cat <<'EOF' > /var/run/add_iptables.sh
        #!/bin/sh
        if [ -z "$3" ]
        then
             echo "Called with host address missing, ignore"
             exit 0
        fi
        echo "Adding ICMP drop rule for '$3' "
        if iptables -C AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        then
             echo "iptables already set for $3"
        else
             iptables -A AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        fi
        EOF

        echo "I$(date "+%m%d %H:%M:%S.%N") - drop-icmp - start drop-icmp ${K8S_NODE}"
        iptables -X AZURE_CHECK_ICMP_SOURCE || true
        iptables -N AZURE_CHECK_ICMP_SOURCE || true
        iptables -F AZURE_CHECK_ICMP_SOURCE
        iptables -D INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE || true
        iptables -I INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE
        iptables -N AZURE_ICMP_ACTION || true
        iptables -F AZURE_ICMP_ACTION
        iptables -A AZURE_ICMP_ACTION -j LOG
        iptables -A AZURE_ICMP_ACTION -j DROP
        /host/usr/bin/oc observe pods -n openshift-sdn -l app=sdn -a '{ .status.hostIP }' -- /var/run/add_iptables.sh
      env:
      - name: K8S_NODE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/bash
            - -c
            - echo drop-icmp done
      name: drop-icmp
      resources:
        requests:
          cpu: 5m
          memory: 20Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        name: host-slash
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zgd9q
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: sdn-dockercfg-46nvg
    nodeName: ocp4azu-sj2sl-worker-prod-brazilsouth1-mjsb5
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: sdn
    serviceAccountName: sdn
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sdn-config
      name: config
    - configMap:
        defaultMode: 420
        name: env-overrides
        optional: true
      name: env-overrides
    - hostPath:
        path: /etc/sysconfig
        type: ""
      name: etc-sysconfig
    - hostPath:
        path: /lib/modules
        type: ""
      name: host-modules
    - hostPath:
        path: /var/run
        type: ""
      name: host-var-run
    - hostPath:
        path: /run/netns
        type: ""
      name: host-run-netns
    - hostPath:
        path: /var/run/netns
        type: ""
      name: host-var-run-netns
    - hostPath:
        path: /var/run/dbus
        type: ""
      name: host-var-run-dbus
    - hostPath:
        path: /var/run/openvswitch
        type: ""
      name: host-var-run-ovs
    - hostPath:
        path: /var/run/kubernetes
        type: ""
      name: host-var-run-kubernetes
    - hostPath:
        path: /var/run/openshift-sdn
        type: ""
      name: host-var-run-openshift-sdn
    - hostPath:
        path: /
        type: ""
      name: host-slash
    - hostPath:
        path: /var/lib/cni/bin
        type: ""
      name: host-cni-bin
    - hostPath:
        path: /var/run/multus/cni/net.d
        type: ""
      name: host-cni-conf
    - hostPath:
        path: /var/lib/cni/networks/openshift-sdn
        type: ""
      name: host-var-lib-cni-networks-openshift-sdn
    - name: sdn-metrics-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: sdn-metrics-certs
    - name: kube-api-access-zgd9q
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T19:26:48Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T19:27:17Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T19:27:17Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T19:26:47Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://4210783a3ad19395856764ceedbdebbeb9040f9ed24b218fb3aa1545328d7731
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: drop-icmp
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T19:27:16Z"
    - containerID: cri-o://8c0768f9a9ec37ec17405578a0953b5a490ee0f458024d7a26d9ebd097166bcb
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T19:27:16Z"
    - containerID: cri-o://6d35229c1fc82eac0fceb511a16a1db506d4b2ab37dd936fb1500b87f382b577
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: sdn
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T19:27:09Z"
    hostIP: 10.80.80.13
    phase: Running
    podIP: 10.80.80.13
    podIPs:
    - ip: 10.80.80.13
    qosClass: Burstable
    startTime: "2023-05-25T19:26:48Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-05-04T21:39:44Z"
    generateName: sdn-controller-
    labels:
      app: sdn-controller
      controller-revision-hash: 9f75579f4
      pod-template-generation: "1"
    name: sdn-controller-2mngw
    namespace: openshift-sdn
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sdn-controller
      uid: 0788c071-1c5e-4fd9-8ebd-b2a62178ef7f
    resourceVersion: "114617605"
    uid: 5aa1ff21-59d2-4fca-9ff3-ecfa90e80a0b
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ocp4azu-sj2sl-master-1
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        if [[ -f /env/_master ]]; then
          set -o allexport
          source /env/_master
          set +o allexport
        fi

        exec openshift-sdn-controller \
         --platform-type Azure \
         --v=${OPENSHIFT_SDN_LOG_LEVEL:-2}
      env:
      - name: KUBERNETES_SERVICE_PORT
        value: "6443"
      - name: KUBERNETES_SERVICE_HOST
        value: api-int.ocp4azu.dirtrab.cl
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      name: sdn-controller
      resources:
        requests:
          cpu: 10m
          memory: 50Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /env
        name: env-overrides
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-kb7z7
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail
        TLS_PK=/etc/pki/tls/metrics-certs/tls.key
        TLS_CERT=/etc/pki/tls/metrics-certs/tls.crt

        # As the secret mount is optional we must wait for the files to be present.
        # The service is created in monitor.yaml and this is created in controller.yaml.
        # If it isn't created there is probably an issue so we want to crashloop.
        TS=$(date +%s)
        WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
        HAS_LOGGED_INFO=0

        log_missing_certs(){
            CUR_TS=$(date +%s)
            if [[ "${CUR_TS}" -gt "${WARN_TS}"  ]]; then
              echo $(date -Iseconds) WARN: sdn-controller-metrics-certs not mounted after 20 minutes.
            elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
              echo $(date -Iseconds) INFO: sdn-controller-metrics-certs not mounted. Waiting 20 minutes.
              HAS_LOGGED_INFO=1
            fi
        }

        while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
          log_missing_certs
          sleep 5
        done

        echo $(date -Iseconds) INFO: sdn-controller-metrics-certs mounted, starting kube-rbac-proxy
        exec /usr/bin/kube-rbac-proxy \
          --logtostderr \
          --secure-listen-address=:9106 \
          --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
          --upstream=http://127.0.0.1:29100/ \
          --tls-private-key-file=${TLS_PK} \
          --tls-cert-file=${TLS_CERT}
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9106
        hostPort: 9106
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/tls/metrics-certs
        name: sdn-controller-metrics-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-kb7z7
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ocp4azu-sj2sl-master-1
    nodeSelector:
      node-role.kubernetes.io/master: ""
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: sdn-controller
    serviceAccountName: sdn-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: env-overrides
        optional: true
      name: env-overrides
    - name: sdn-controller-metrics-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: sdn-controller-metrics-certs
    - name: kube-api-access-kb7z7
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-05-04T21:39:44Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-05-11T18:26:20Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-05-11T18:26:20Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-05-04T21:39:44Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://78b3251cb13fcb7aa5b8eb74864b21c5e82c3735ddd6840c488357459a987eea
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2023-05-11T18:26:19Z"
    - containerID: cri-o://061640e1238b326a8dbfc5b82fac5ff34250a4325180a7869837e3c2cb553d9e
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: sdn-controller
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2023-05-11T18:26:19Z"
    hostIP: 10.80.80.8
    phase: Running
    podIP: 10.80.80.8
    podIPs:
    - ip: 10.80.80.8
    qosClass: Burstable
    startTime: "2023-05-04T21:39:44Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-05-04T21:39:44Z"
    generateName: sdn-controller-
    labels:
      app: sdn-controller
      controller-revision-hash: 9f75579f4
      pod-template-generation: "1"
    name: sdn-controller-5vqfv
    namespace: openshift-sdn
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sdn-controller
      uid: 0788c071-1c5e-4fd9-8ebd-b2a62178ef7f
    resourceVersion: "1605422"
    uid: 4c913461-f754-4e67-b219-0d04c4f979f7
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ocp4azu-sj2sl-master-0
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        if [[ -f /env/_master ]]; then
          set -o allexport
          source /env/_master
          set +o allexport
        fi

        exec openshift-sdn-controller \
         --platform-type Azure \
         --v=${OPENSHIFT_SDN_LOG_LEVEL:-2}
      env:
      - name: KUBERNETES_SERVICE_PORT
        value: "6443"
      - name: KUBERNETES_SERVICE_HOST
        value: api-int.ocp4azu.dirtrab.cl
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      name: sdn-controller
      resources:
        requests:
          cpu: 10m
          memory: 50Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /env
        name: env-overrides
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-d77zz
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail
        TLS_PK=/etc/pki/tls/metrics-certs/tls.key
        TLS_CERT=/etc/pki/tls/metrics-certs/tls.crt

        # As the secret mount is optional we must wait for the files to be present.
        # The service is created in monitor.yaml and this is created in controller.yaml.
        # If it isn't created there is probably an issue so we want to crashloop.
        TS=$(date +%s)
        WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
        HAS_LOGGED_INFO=0

        log_missing_certs(){
            CUR_TS=$(date +%s)
            if [[ "${CUR_TS}" -gt "${WARN_TS}"  ]]; then
              echo $(date -Iseconds) WARN: sdn-controller-metrics-certs not mounted after 20 minutes.
            elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
              echo $(date -Iseconds) INFO: sdn-controller-metrics-certs not mounted. Waiting 20 minutes.
              HAS_LOGGED_INFO=1
            fi
        }

        while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
          log_missing_certs
          sleep 5
        done

        echo $(date -Iseconds) INFO: sdn-controller-metrics-certs mounted, starting kube-rbac-proxy
        exec /usr/bin/kube-rbac-proxy \
          --logtostderr \
          --secure-listen-address=:9106 \
          --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
          --upstream=http://127.0.0.1:29100/ \
          --tls-private-key-file=${TLS_PK} \
          --tls-cert-file=${TLS_CERT}
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9106
        hostPort: 9106
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/tls/metrics-certs
        name: sdn-controller-metrics-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-d77zz
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ocp4azu-sj2sl-master-0
    nodeSelector:
      node-role.kubernetes.io/master: ""
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: sdn-controller
    serviceAccountName: sdn-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: env-overrides
        optional: true
      name: env-overrides
    - name: sdn-controller-metrics-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: sdn-controller-metrics-certs
    - name: kube-api-access-d77zz
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-05-04T21:39:44Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-05-11T18:26:14Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-05-11T18:26:14Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-05-04T21:39:44Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://089fe9c1180396f6ad6dc1cfdfc1655fd3efee2e5a4d2d04a167029927d717c6
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2023-05-11T18:26:13Z"
    - containerID: cri-o://46cae3b96f659a897ad44aec9d11bb8aefcf3c53bac4cd21c836e5eecc7198a0
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: sdn-controller
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2023-05-11T18:26:13Z"
    hostIP: 10.80.80.6
    phase: Running
    podIP: 10.80.80.6
    podIPs:
    - ip: 10.80.80.6
    qosClass: Burstable
    startTime: "2023-05-04T21:39:44Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-05-04T21:39:44Z"
    generateName: sdn-controller-
    labels:
      app: sdn-controller
      controller-revision-hash: 9f75579f4
      pod-template-generation: "1"
    name: sdn-controller-ktfzx
    namespace: openshift-sdn
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sdn-controller
      uid: 0788c071-1c5e-4fd9-8ebd-b2a62178ef7f
    resourceVersion: "465633631"
    uid: f1b4693a-036a-473a-9064-322af9647ca1
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ocp4azu-sj2sl-master-2
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        if [[ -f /env/_master ]]; then
          set -o allexport
          source /env/_master
          set +o allexport
        fi

        exec openshift-sdn-controller \
         --platform-type Azure \
         --v=${OPENSHIFT_SDN_LOG_LEVEL:-2}
      env:
      - name: KUBERNETES_SERVICE_PORT
        value: "6443"
      - name: KUBERNETES_SERVICE_HOST
        value: api-int.ocp4azu.dirtrab.cl
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      name: sdn-controller
      resources:
        requests:
          cpu: 10m
          memory: 50Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /env
        name: env-overrides
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-g8wgg
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail
        TLS_PK=/etc/pki/tls/metrics-certs/tls.key
        TLS_CERT=/etc/pki/tls/metrics-certs/tls.crt

        # As the secret mount is optional we must wait for the files to be present.
        # The service is created in monitor.yaml and this is created in controller.yaml.
        # If it isn't created there is probably an issue so we want to crashloop.
        TS=$(date +%s)
        WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
        HAS_LOGGED_INFO=0

        log_missing_certs(){
            CUR_TS=$(date +%s)
            if [[ "${CUR_TS}" -gt "${WARN_TS}"  ]]; then
              echo $(date -Iseconds) WARN: sdn-controller-metrics-certs not mounted after 20 minutes.
            elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
              echo $(date -Iseconds) INFO: sdn-controller-metrics-certs not mounted. Waiting 20 minutes.
              HAS_LOGGED_INFO=1
            fi
        }

        while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
          log_missing_certs
          sleep 5
        done

        echo $(date -Iseconds) INFO: sdn-controller-metrics-certs mounted, starting kube-rbac-proxy
        exec /usr/bin/kube-rbac-proxy \
          --logtostderr \
          --secure-listen-address=:9106 \
          --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
          --upstream=http://127.0.0.1:29100/ \
          --tls-private-key-file=${TLS_PK} \
          --tls-cert-file=${TLS_CERT}
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9106
        hostPort: 9106
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/tls/metrics-certs
        name: sdn-controller-metrics-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-g8wgg
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ocp4azu-sj2sl-master-2
    nodeSelector:
      node-role.kubernetes.io/master: ""
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext:
      runAsNonRoot: true
      runAsUser: 65534
    serviceAccount: sdn-controller
    serviceAccountName: sdn-controller
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/network-unavailable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: env-overrides
        optional: true
      name: env-overrides
    - name: sdn-controller-metrics-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: sdn-controller-metrics-certs
    - name: kube-api-access-g8wgg
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-05-04T21:39:44Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-05-11T18:26:14Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-05-11T18:26:14Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-05-04T21:39:44Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://b7da10da10126975a8008430a55f4f5a42a7b76e012193b74f69fe84303c2569
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2023-05-11T18:26:13Z"
    - containerID: cri-o://adaea0efd3f50df2388a2e8100f43bfbf28d4697d129c2f0cdd65c77da698b0c
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: sdn-controller
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2023-05-11T18:26:12Z"
    hostIP: 10.80.80.7
    phase: Running
    podIP: 10.80.80.7
    podIPs:
    - ip: 10.80.80.7
    qosClass: Burstable
    startTime: "2023-05-04T21:39:44Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-05-16T16:46:16Z"
    generateName: sdn-
    labels:
      app: sdn
      component: network
      controller-revision-hash: 749f49c4cc
      openshift.io/component: network
      pod-template-generation: "1"
      type: infra
    name: sdn-dknq8
    namespace: openshift-sdn
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sdn
      uid: 79c4ac3b-dde1-4470-a005-a221cb9e48d9
    resourceVersion: "467286821"
    uid: 028c0590-928e-45a1-b60a-a136a2d26ec7
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ocp4azu-sj2sl-infra-brazilsouth3-pfrpx
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail

        # if another process is listening on the cni-server socket, wait until it exits
        trap 'kill $(jobs -p); rm -f /etc/cni/net.d/80-openshift-network.conf ; exit 0' TERM
        retries=0
        while true; do
          if echo 'test' | socat - UNIX-CONNECT:/var/run/openshift-sdn/cniserver/socket &>/dev/null; then
            echo "warning: Another process is currently listening on the CNI socket, waiting 15s ..." 2>&1
            sleep 15 & wait
            (( retries += 1 ))
          else
            break
          fi
          if [[ "${retries}" -gt 40 ]]; then
            echo "error: Another process is currently listening on the CNI socket, exiting" 2>&1
            exit 1
          fi
        done

        # local environment overrides
        if [[ -f /etc/sysconfig/openshift-sdn ]]; then
          set -o allexport
          source /etc/sysconfig/openshift-sdn
          set +o allexport
        fi
        #BUG: cdc accidentally mounted /etc/sysconfig/openshift-sdn as DirectoryOrCreate; clean it up so we can ultimately mount /etc/sysconfig/openshift-sdn as FileOrCreate
        # Once this is released, then we can mount it properly
        if [[ -d /etc/sysconfig/openshift-sdn ]]; then
          rmdir /etc/sysconfig/openshift-sdn || true
        fi

        # configmap-based overrides
        if [[ -f /env/${K8S_NODE_NAME} ]]; then
          set -o allexport
          source /env/${K8S_NODE_NAME}
          set +o allexport
        fi

        # Take over network functions on the node
        rm -f /etc/cni/net.d/80-openshift-network.conf
        cp -f /opt/cni/bin/openshift-sdn /host-cni-bin/

        mtu_override_flag=
        if [[ -f /config/mtu.yaml ]]; then
          mtu_override_flag="--mtu-override /config/mtu.yaml"
        fi

        # Launch the network process
        exec /usr/bin/openshift-sdn-node \
          --node-name ${K8S_NODE_NAME} --node-ip ${K8S_NODE_IP} \
          --platform-type Azure \
          --proxy-config /config/kube-proxy-config.yaml \
          ${mtu_override_flag} \
          --v ${OPENSHIFT_SDN_LOG_LEVEL:-2}
      env:
      - name: KUBERNETES_SERVICE_PORT
        value: "6443"
      - name: KUBERNETES_SERVICE_HOST
        value: api-int.ocp4azu.dirtrab.cl
      - name: OPENSHIFT_DNS_DOMAIN
        value: cluster.local
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: K8S_NODE_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - rm
            - -f
            - /etc/cni/net.d/80-openshift-network.conf
            - /host-cni-bin/openshift-sdn
      name: sdn
      ports:
      - containerPort: 10256
        hostPort: 10256
        name: healthz
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - test
          - -f
          - /etc/cni/net.d/80-openshift-network.conf
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /config
        name: config
        readOnly: true
      - mountPath: /env
        name: env-overrides
      - mountPath: /var/run
        name: host-var-run
      - mountPath: /var/run/dbus/
        name: host-var-run-dbus
        readOnly: true
      - mountPath: /var/run/openvswitch/
        name: host-var-run-ovs
        readOnly: true
      - mountPath: /var/run/kubernetes/
        name: host-var-run-kubernetes
        readOnly: true
      - mountPath: /run/netns
        mountPropagation: HostToContainer
        name: host-run-netns
        readOnly: true
      - mountPath: /host/var/run/netns
        mountPropagation: HostToContainer
        name: host-var-run-netns
        readOnly: true
      - mountPath: /var/run/openshift-sdn
        name: host-var-run-openshift-sdn
      - mountPath: /host
        mountPropagation: HostToContainer
        name: host-slash
        readOnly: true
      - mountPath: /host-cni-bin
        name: host-cni-bin
      - mountPath: /etc/cni/net.d
        name: host-cni-conf
      - mountPath: /var/lib/cni/networks/openshift-sdn
        name: host-var-lib-cni-networks-openshift-sdn
      - mountPath: /lib/modules
        name: host-modules
        readOnly: true
      - mountPath: /etc/sysconfig
        name: etc-sysconfig
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zml7s
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail
        TLS_PK=/etc/pki/tls/metrics-certs/tls.key
        TLS_CERT=/etc/pki/tls/metrics-certs/tls.crt

        # As the secret mount is optional we must wait for the files to be present.
        # The service is created in monitor.yaml and this is created in sdn.yaml.
        # If it isn't created there is probably an issue so we want to crashloop.
        TS=$(date +%s)
        WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
        HAS_LOGGED_INFO=0

        log_missing_certs(){
            CUR_TS=$(date +%s)
            if [[ "${CUR_TS}" -gt "WARN_TS"  ]]; then
              echo $(date -Iseconds) WARN: sdn-metrics-certs not mounted after 20 minutes.
            elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
              echo $(date -Iseconds) INFO: sdn-metrics-certs not mounted. Waiting 20 minutes.
              HAS_LOGGED_INFO=1
            fi
        }

        while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
          log_missing_certs
          sleep 5
        done

        echo $(date -Iseconds) INFO: sdn-metrics-certs mounted, starting kube-rbac-proxy
        exec /usr/bin/kube-rbac-proxy \
          --logtostderr \
          --secure-listen-address=:9101 \
          --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
          --upstream=http://127.0.0.1:29101/ \
          --tls-private-key-file=${TLS_PK} \
          --tls-cert-file=${TLS_CERT}
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9101
        hostPort: 9101
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/tls/metrics-certs
        name: sdn-metrics-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zml7s
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        set -xe

        touch /var/run/add_iptables.sh
        chmod 0755 /var/run/add_iptables.sh
        cat <<'EOF' > /var/run/add_iptables.sh
        #!/bin/sh
        if [ -z "$3" ]
        then
             echo "Called with host address missing, ignore"
             exit 0
        fi
        echo "Adding ICMP drop rule for '$3' "
        if iptables -C AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        then
             echo "iptables already set for $3"
        else
             iptables -A AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        fi
        EOF

        echo "I$(date "+%m%d %H:%M:%S.%N") - drop-icmp - start drop-icmp ${K8S_NODE}"
        iptables -X AZURE_CHECK_ICMP_SOURCE || true
        iptables -N AZURE_CHECK_ICMP_SOURCE || true
        iptables -F AZURE_CHECK_ICMP_SOURCE
        iptables -D INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE || true
        iptables -I INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE
        iptables -N AZURE_ICMP_ACTION || true
        iptables -F AZURE_ICMP_ACTION
        iptables -A AZURE_ICMP_ACTION -j LOG
        iptables -A AZURE_ICMP_ACTION -j DROP
        /host/usr/bin/oc observe pods -n openshift-sdn -l app=sdn -a '{ .status.hostIP }' -- /var/run/add_iptables.sh
      env:
      - name: K8S_NODE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/bash
            - -c
            - echo drop-icmp done
      name: drop-icmp
      resources:
        requests:
          cpu: 5m
          memory: 20Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        name: host-slash
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zml7s
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: sdn-dockercfg-46nvg
    nodeName: ocp4azu-sj2sl-infra-brazilsouth3-pfrpx
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: sdn
    serviceAccountName: sdn
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sdn-config
      name: config
    - configMap:
        defaultMode: 420
        name: env-overrides
        optional: true
      name: env-overrides
    - hostPath:
        path: /etc/sysconfig
        type: ""
      name: etc-sysconfig
    - hostPath:
        path: /lib/modules
        type: ""
      name: host-modules
    - hostPath:
        path: /var/run
        type: ""
      name: host-var-run
    - hostPath:
        path: /run/netns
        type: ""
      name: host-run-netns
    - hostPath:
        path: /var/run/netns
        type: ""
      name: host-var-run-netns
    - hostPath:
        path: /var/run/dbus
        type: ""
      name: host-var-run-dbus
    - hostPath:
        path: /var/run/openvswitch
        type: ""
      name: host-var-run-ovs
    - hostPath:
        path: /var/run/kubernetes
        type: ""
      name: host-var-run-kubernetes
    - hostPath:
        path: /var/run/openshift-sdn
        type: ""
      name: host-var-run-openshift-sdn
    - hostPath:
        path: /
        type: ""
      name: host-slash
    - hostPath:
        path: /var/lib/cni/bin
        type: ""
      name: host-cni-bin
    - hostPath:
        path: /var/run/multus/cni/net.d
        type: ""
      name: host-cni-conf
    - hostPath:
        path: /var/lib/cni/networks/openshift-sdn
        type: ""
      name: host-var-lib-cni-networks-openshift-sdn
    - name: sdn-metrics-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: sdn-metrics-certs
    - name: kube-api-access-zml7s
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-05-16T16:46:17Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-05-16T16:46:40Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-05-16T16:46:40Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-05-16T16:46:16Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://fe1330c9b765017672455f7c546c63fc1b2698b1667c1951b706b87632d0eebf
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: drop-icmp
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-16T16:46:39Z"
    - containerID: cri-o://cc28469a77271ac6516670f6ff57a6bfbbb482687344c509f200db2e1ae6b588
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-16T16:46:39Z"
    - containerID: cri-o://e4e36e84b879dda076533b7e4873be4a2206719d743473e031e0faf55568cf42
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: sdn
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-16T16:46:34Z"
    hostIP: 10.80.80.16
    phase: Running
    podIP: 10.80.80.16
    podIPs:
    - ip: 10.80.80.16
    qosClass: Burstable
    startTime: "2023-05-16T16:46:17Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-05-25T20:10:15Z"
    generateName: sdn-
    labels:
      app: sdn
      component: network
      controller-revision-hash: 749f49c4cc
      openshift.io/component: network
      pod-template-generation: "1"
      type: infra
    name: sdn-jhvsf
    namespace: openshift-sdn
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sdn
      uid: 79c4ac3b-dde1-4470-a005-a221cb9e48d9
    resourceVersion: "428583598"
    uid: a18e7bc1-844d-492b-ad5e-4737f93c33d7
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ocp4azu-sj2sl-worker-prod-brazilsouth2-gmw4z
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail

        # if another process is listening on the cni-server socket, wait until it exits
        trap 'kill $(jobs -p); rm -f /etc/cni/net.d/80-openshift-network.conf ; exit 0' TERM
        retries=0
        while true; do
          if echo 'test' | socat - UNIX-CONNECT:/var/run/openshift-sdn/cniserver/socket &>/dev/null; then
            echo "warning: Another process is currently listening on the CNI socket, waiting 15s ..." 2>&1
            sleep 15 & wait
            (( retries += 1 ))
          else
            break
          fi
          if [[ "${retries}" -gt 40 ]]; then
            echo "error: Another process is currently listening on the CNI socket, exiting" 2>&1
            exit 1
          fi
        done

        # local environment overrides
        if [[ -f /etc/sysconfig/openshift-sdn ]]; then
          set -o allexport
          source /etc/sysconfig/openshift-sdn
          set +o allexport
        fi
        #BUG: cdc accidentally mounted /etc/sysconfig/openshift-sdn as DirectoryOrCreate; clean it up so we can ultimately mount /etc/sysconfig/openshift-sdn as FileOrCreate
        # Once this is released, then we can mount it properly
        if [[ -d /etc/sysconfig/openshift-sdn ]]; then
          rmdir /etc/sysconfig/openshift-sdn || true
        fi

        # configmap-based overrides
        if [[ -f /env/${K8S_NODE_NAME} ]]; then
          set -o allexport
          source /env/${K8S_NODE_NAME}
          set +o allexport
        fi

        # Take over network functions on the node
        rm -f /etc/cni/net.d/80-openshift-network.conf
        cp -f /opt/cni/bin/openshift-sdn /host-cni-bin/

        mtu_override_flag=
        if [[ -f /config/mtu.yaml ]]; then
          mtu_override_flag="--mtu-override /config/mtu.yaml"
        fi

        # Launch the network process
        exec /usr/bin/openshift-sdn-node \
          --node-name ${K8S_NODE_NAME} --node-ip ${K8S_NODE_IP} \
          --platform-type Azure \
          --proxy-config /config/kube-proxy-config.yaml \
          ${mtu_override_flag} \
          --v ${OPENSHIFT_SDN_LOG_LEVEL:-2}
      env:
      - name: KUBERNETES_SERVICE_PORT
        value: "6443"
      - name: KUBERNETES_SERVICE_HOST
        value: api-int.ocp4azu.dirtrab.cl
      - name: OPENSHIFT_DNS_DOMAIN
        value: cluster.local
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: K8S_NODE_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - rm
            - -f
            - /etc/cni/net.d/80-openshift-network.conf
            - /host-cni-bin/openshift-sdn
      name: sdn
      ports:
      - containerPort: 10256
        hostPort: 10256
        name: healthz
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - test
          - -f
          - /etc/cni/net.d/80-openshift-network.conf
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /config
        name: config
        readOnly: true
      - mountPath: /env
        name: env-overrides
      - mountPath: /var/run
        name: host-var-run
      - mountPath: /var/run/dbus/
        name: host-var-run-dbus
        readOnly: true
      - mountPath: /var/run/openvswitch/
        name: host-var-run-ovs
        readOnly: true
      - mountPath: /var/run/kubernetes/
        name: host-var-run-kubernetes
        readOnly: true
      - mountPath: /run/netns
        mountPropagation: HostToContainer
        name: host-run-netns
        readOnly: true
      - mountPath: /host/var/run/netns
        mountPropagation: HostToContainer
        name: host-var-run-netns
        readOnly: true
      - mountPath: /var/run/openshift-sdn
        name: host-var-run-openshift-sdn
      - mountPath: /host
        mountPropagation: HostToContainer
        name: host-slash
        readOnly: true
      - mountPath: /host-cni-bin
        name: host-cni-bin
      - mountPath: /etc/cni/net.d
        name: host-cni-conf
      - mountPath: /var/lib/cni/networks/openshift-sdn
        name: host-var-lib-cni-networks-openshift-sdn
      - mountPath: /lib/modules
        name: host-modules
        readOnly: true
      - mountPath: /etc/sysconfig
        name: etc-sysconfig
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-t8x5m
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail
        TLS_PK=/etc/pki/tls/metrics-certs/tls.key
        TLS_CERT=/etc/pki/tls/metrics-certs/tls.crt

        # As the secret mount is optional we must wait for the files to be present.
        # The service is created in monitor.yaml and this is created in sdn.yaml.
        # If it isn't created there is probably an issue so we want to crashloop.
        TS=$(date +%s)
        WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
        HAS_LOGGED_INFO=0

        log_missing_certs(){
            CUR_TS=$(date +%s)
            if [[ "${CUR_TS}" -gt "WARN_TS"  ]]; then
              echo $(date -Iseconds) WARN: sdn-metrics-certs not mounted after 20 minutes.
            elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
              echo $(date -Iseconds) INFO: sdn-metrics-certs not mounted. Waiting 20 minutes.
              HAS_LOGGED_INFO=1
            fi
        }

        while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
          log_missing_certs
          sleep 5
        done

        echo $(date -Iseconds) INFO: sdn-metrics-certs mounted, starting kube-rbac-proxy
        exec /usr/bin/kube-rbac-proxy \
          --logtostderr \
          --secure-listen-address=:9101 \
          --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
          --upstream=http://127.0.0.1:29101/ \
          --tls-private-key-file=${TLS_PK} \
          --tls-cert-file=${TLS_CERT}
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9101
        hostPort: 9101
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/tls/metrics-certs
        name: sdn-metrics-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-t8x5m
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        set -xe

        touch /var/run/add_iptables.sh
        chmod 0755 /var/run/add_iptables.sh
        cat <<'EOF' > /var/run/add_iptables.sh
        #!/bin/sh
        if [ -z "$3" ]
        then
             echo "Called with host address missing, ignore"
             exit 0
        fi
        echo "Adding ICMP drop rule for '$3' "
        if iptables -C AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        then
             echo "iptables already set for $3"
        else
             iptables -A AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        fi
        EOF

        echo "I$(date "+%m%d %H:%M:%S.%N") - drop-icmp - start drop-icmp ${K8S_NODE}"
        iptables -X AZURE_CHECK_ICMP_SOURCE || true
        iptables -N AZURE_CHECK_ICMP_SOURCE || true
        iptables -F AZURE_CHECK_ICMP_SOURCE
        iptables -D INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE || true
        iptables -I INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE
        iptables -N AZURE_ICMP_ACTION || true
        iptables -F AZURE_ICMP_ACTION
        iptables -A AZURE_ICMP_ACTION -j LOG
        iptables -A AZURE_ICMP_ACTION -j DROP
        /host/usr/bin/oc observe pods -n openshift-sdn -l app=sdn -a '{ .status.hostIP }' -- /var/run/add_iptables.sh
      env:
      - name: K8S_NODE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/bash
            - -c
            - echo drop-icmp done
      name: drop-icmp
      resources:
        requests:
          cpu: 5m
          memory: 20Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        name: host-slash
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-t8x5m
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: sdn-dockercfg-46nvg
    nodeName: ocp4azu-sj2sl-worker-prod-brazilsouth2-gmw4z
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: sdn
    serviceAccountName: sdn
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sdn-config
      name: config
    - configMap:
        defaultMode: 420
        name: env-overrides
        optional: true
      name: env-overrides
    - hostPath:
        path: /etc/sysconfig
        type: ""
      name: etc-sysconfig
    - hostPath:
        path: /lib/modules
        type: ""
      name: host-modules
    - hostPath:
        path: /var/run
        type: ""
      name: host-var-run
    - hostPath:
        path: /run/netns
        type: ""
      name: host-run-netns
    - hostPath:
        path: /var/run/netns
        type: ""
      name: host-var-run-netns
    - hostPath:
        path: /var/run/dbus
        type: ""
      name: host-var-run-dbus
    - hostPath:
        path: /var/run/openvswitch
        type: ""
      name: host-var-run-ovs
    - hostPath:
        path: /var/run/kubernetes
        type: ""
      name: host-var-run-kubernetes
    - hostPath:
        path: /var/run/openshift-sdn
        type: ""
      name: host-var-run-openshift-sdn
    - hostPath:
        path: /
        type: ""
      name: host-slash
    - hostPath:
        path: /var/lib/cni/bin
        type: ""
      name: host-cni-bin
    - hostPath:
        path: /var/run/multus/cni/net.d
        type: ""
      name: host-cni-conf
    - hostPath:
        path: /var/lib/cni/networks/openshift-sdn
        type: ""
      name: host-var-lib-cni-networks-openshift-sdn
    - name: sdn-metrics-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: sdn-metrics-certs
    - name: kube-api-access-t8x5m
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T20:10:16Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T20:10:41Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T20:10:41Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T20:10:15Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://8b540294d5066b00f1c7916a8fec4d2e23370abf80d69076e1a228f880448466
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: drop-icmp
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T20:10:40Z"
    - containerID: cri-o://e18ead3571155a2bddfedd6ae767de7bda1bcded615c248df8c11829bc0bc510
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T20:10:40Z"
    - containerID: cri-o://2e14d16e669992f0cbb94cfc4e16deebcb8e81aa052243ad25e6163ed49cd914
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: sdn
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T20:10:35Z"
    hostIP: 10.80.80.17
    phase: Running
    podIP: 10.80.80.17
    podIPs:
    - ip: 10.80.80.17
    qosClass: Burstable
    startTime: "2023-05-25T20:10:16Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-05-16T17:01:44Z"
    generateName: sdn-
    labels:
      app: sdn
      component: network
      controller-revision-hash: 749f49c4cc
      openshift.io/component: network
      pod-template-generation: "1"
      type: infra
    name: sdn-jt48k
    namespace: openshift-sdn
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sdn
      uid: 79c4ac3b-dde1-4470-a005-a221cb9e48d9
    resourceVersion: "458211540"
    uid: 3caaf66b-9ec2-4908-9502-95f97c62fb7c
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ocp4azu-sj2sl-infra-brazilsouth2-ptg7h
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail

        # if another process is listening on the cni-server socket, wait until it exits
        trap 'kill $(jobs -p); rm -f /etc/cni/net.d/80-openshift-network.conf ; exit 0' TERM
        retries=0
        while true; do
          if echo 'test' | socat - UNIX-CONNECT:/var/run/openshift-sdn/cniserver/socket &>/dev/null; then
            echo "warning: Another process is currently listening on the CNI socket, waiting 15s ..." 2>&1
            sleep 15 & wait
            (( retries += 1 ))
          else
            break
          fi
          if [[ "${retries}" -gt 40 ]]; then
            echo "error: Another process is currently listening on the CNI socket, exiting" 2>&1
            exit 1
          fi
        done

        # local environment overrides
        if [[ -f /etc/sysconfig/openshift-sdn ]]; then
          set -o allexport
          source /etc/sysconfig/openshift-sdn
          set +o allexport
        fi
        #BUG: cdc accidentally mounted /etc/sysconfig/openshift-sdn as DirectoryOrCreate; clean it up so we can ultimately mount /etc/sysconfig/openshift-sdn as FileOrCreate
        # Once this is released, then we can mount it properly
        if [[ -d /etc/sysconfig/openshift-sdn ]]; then
          rmdir /etc/sysconfig/openshift-sdn || true
        fi

        # configmap-based overrides
        if [[ -f /env/${K8S_NODE_NAME} ]]; then
          set -o allexport
          source /env/${K8S_NODE_NAME}
          set +o allexport
        fi

        # Take over network functions on the node
        rm -f /etc/cni/net.d/80-openshift-network.conf
        cp -f /opt/cni/bin/openshift-sdn /host-cni-bin/

        mtu_override_flag=
        if [[ -f /config/mtu.yaml ]]; then
          mtu_override_flag="--mtu-override /config/mtu.yaml"
        fi

        # Launch the network process
        exec /usr/bin/openshift-sdn-node \
          --node-name ${K8S_NODE_NAME} --node-ip ${K8S_NODE_IP} \
          --platform-type Azure \
          --proxy-config /config/kube-proxy-config.yaml \
          ${mtu_override_flag} \
          --v ${OPENSHIFT_SDN_LOG_LEVEL:-2}
      env:
      - name: KUBERNETES_SERVICE_PORT
        value: "6443"
      - name: KUBERNETES_SERVICE_HOST
        value: api-int.ocp4azu.dirtrab.cl
      - name: OPENSHIFT_DNS_DOMAIN
        value: cluster.local
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: K8S_NODE_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - rm
            - -f
            - /etc/cni/net.d/80-openshift-network.conf
            - /host-cni-bin/openshift-sdn
      name: sdn
      ports:
      - containerPort: 10256
        hostPort: 10256
        name: healthz
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - test
          - -f
          - /etc/cni/net.d/80-openshift-network.conf
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /config
        name: config
        readOnly: true
      - mountPath: /env
        name: env-overrides
      - mountPath: /var/run
        name: host-var-run
      - mountPath: /var/run/dbus/
        name: host-var-run-dbus
        readOnly: true
      - mountPath: /var/run/openvswitch/
        name: host-var-run-ovs
        readOnly: true
      - mountPath: /var/run/kubernetes/
        name: host-var-run-kubernetes
        readOnly: true
      - mountPath: /run/netns
        mountPropagation: HostToContainer
        name: host-run-netns
        readOnly: true
      - mountPath: /host/var/run/netns
        mountPropagation: HostToContainer
        name: host-var-run-netns
        readOnly: true
      - mountPath: /var/run/openshift-sdn
        name: host-var-run-openshift-sdn
      - mountPath: /host
        mountPropagation: HostToContainer
        name: host-slash
        readOnly: true
      - mountPath: /host-cni-bin
        name: host-cni-bin
      - mountPath: /etc/cni/net.d
        name: host-cni-conf
      - mountPath: /var/lib/cni/networks/openshift-sdn
        name: host-var-lib-cni-networks-openshift-sdn
      - mountPath: /lib/modules
        name: host-modules
        readOnly: true
      - mountPath: /etc/sysconfig
        name: etc-sysconfig
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-df2nm
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail
        TLS_PK=/etc/pki/tls/metrics-certs/tls.key
        TLS_CERT=/etc/pki/tls/metrics-certs/tls.crt

        # As the secret mount is optional we must wait for the files to be present.
        # The service is created in monitor.yaml and this is created in sdn.yaml.
        # If it isn't created there is probably an issue so we want to crashloop.
        TS=$(date +%s)
        WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
        HAS_LOGGED_INFO=0

        log_missing_certs(){
            CUR_TS=$(date +%s)
            if [[ "${CUR_TS}" -gt "WARN_TS"  ]]; then
              echo $(date -Iseconds) WARN: sdn-metrics-certs not mounted after 20 minutes.
            elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
              echo $(date -Iseconds) INFO: sdn-metrics-certs not mounted. Waiting 20 minutes.
              HAS_LOGGED_INFO=1
            fi
        }

        while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
          log_missing_certs
          sleep 5
        done

        echo $(date -Iseconds) INFO: sdn-metrics-certs mounted, starting kube-rbac-proxy
        exec /usr/bin/kube-rbac-proxy \
          --logtostderr \
          --secure-listen-address=:9101 \
          --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
          --upstream=http://127.0.0.1:29101/ \
          --tls-private-key-file=${TLS_PK} \
          --tls-cert-file=${TLS_CERT}
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9101
        hostPort: 9101
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/tls/metrics-certs
        name: sdn-metrics-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-df2nm
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        set -xe

        touch /var/run/add_iptables.sh
        chmod 0755 /var/run/add_iptables.sh
        cat <<'EOF' > /var/run/add_iptables.sh
        #!/bin/sh
        if [ -z "$3" ]
        then
             echo "Called with host address missing, ignore"
             exit 0
        fi
        echo "Adding ICMP drop rule for '$3' "
        if iptables -C AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        then
             echo "iptables already set for $3"
        else
             iptables -A AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        fi
        EOF

        echo "I$(date "+%m%d %H:%M:%S.%N") - drop-icmp - start drop-icmp ${K8S_NODE}"
        iptables -X AZURE_CHECK_ICMP_SOURCE || true
        iptables -N AZURE_CHECK_ICMP_SOURCE || true
        iptables -F AZURE_CHECK_ICMP_SOURCE
        iptables -D INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE || true
        iptables -I INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE
        iptables -N AZURE_ICMP_ACTION || true
        iptables -F AZURE_ICMP_ACTION
        iptables -A AZURE_ICMP_ACTION -j LOG
        iptables -A AZURE_ICMP_ACTION -j DROP
        /host/usr/bin/oc observe pods -n openshift-sdn -l app=sdn -a '{ .status.hostIP }' -- /var/run/add_iptables.sh
      env:
      - name: K8S_NODE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/bash
            - -c
            - echo drop-icmp done
      name: drop-icmp
      resources:
        requests:
          cpu: 5m
          memory: 20Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        name: host-slash
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-df2nm
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: sdn-dockercfg-46nvg
    nodeName: ocp4azu-sj2sl-infra-brazilsouth2-ptg7h
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: sdn
    serviceAccountName: sdn
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sdn-config
      name: config
    - configMap:
        defaultMode: 420
        name: env-overrides
        optional: true
      name: env-overrides
    - hostPath:
        path: /etc/sysconfig
        type: ""
      name: etc-sysconfig
    - hostPath:
        path: /lib/modules
        type: ""
      name: host-modules
    - hostPath:
        path: /var/run
        type: ""
      name: host-var-run
    - hostPath:
        path: /run/netns
        type: ""
      name: host-run-netns
    - hostPath:
        path: /var/run/netns
        type: ""
      name: host-var-run-netns
    - hostPath:
        path: /var/run/dbus
        type: ""
      name: host-var-run-dbus
    - hostPath:
        path: /var/run/openvswitch
        type: ""
      name: host-var-run-ovs
    - hostPath:
        path: /var/run/kubernetes
        type: ""
      name: host-var-run-kubernetes
    - hostPath:
        path: /var/run/openshift-sdn
        type: ""
      name: host-var-run-openshift-sdn
    - hostPath:
        path: /
        type: ""
      name: host-slash
    - hostPath:
        path: /var/lib/cni/bin
        type: ""
      name: host-cni-bin
    - hostPath:
        path: /var/run/multus/cni/net.d
        type: ""
      name: host-cni-conf
    - hostPath:
        path: /var/lib/cni/networks/openshift-sdn
        type: ""
      name: host-var-lib-cni-networks-openshift-sdn
    - name: sdn-metrics-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: sdn-metrics-certs
    - name: kube-api-access-df2nm
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-05-16T17:01:44Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-05-16T17:02:09Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-05-16T17:02:09Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-05-16T17:01:44Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://a5dbdb669c5a165968a83ef79e8ca754ab692b5959882dbb2bbb6feef43edb4a
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: drop-icmp
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-16T17:02:08Z"
    - containerID: cri-o://724be2f121321957a10bafba313d475c6f8c701a1a12e94bea19a3a5b737af0c
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-16T17:02:08Z"
    - containerID: cri-o://db100198f746538c997c4a160cf2d5295e7d1ff3a9aa61d3e5fbbc8206ae955f
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: sdn
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-16T17:02:03Z"
    hostIP: 10.80.80.12
    phase: Running
    podIP: 10.80.80.12
    podIPs:
    - ip: 10.80.80.12
    qosClass: Burstable
    startTime: "2023-05-16T17:01:44Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-05-04T21:39:44Z"
    generateName: sdn-
    labels:
      app: sdn
      component: network
      controller-revision-hash: 749f49c4cc
      openshift.io/component: network
      pod-template-generation: "1"
      type: infra
    name: sdn-kqn92
    namespace: openshift-sdn
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sdn
      uid: 79c4ac3b-dde1-4470-a005-a221cb9e48d9
    resourceVersion: "465633571"
    uid: 13e2c7ed-40d2-4c1f-bf29-020631ed3f22
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ocp4azu-sj2sl-master-2
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail

        # if another process is listening on the cni-server socket, wait until it exits
        trap 'kill $(jobs -p); rm -f /etc/cni/net.d/80-openshift-network.conf ; exit 0' TERM
        retries=0
        while true; do
          if echo 'test' | socat - UNIX-CONNECT:/var/run/openshift-sdn/cniserver/socket &>/dev/null; then
            echo "warning: Another process is currently listening on the CNI socket, waiting 15s ..." 2>&1
            sleep 15 & wait
            (( retries += 1 ))
          else
            break
          fi
          if [[ "${retries}" -gt 40 ]]; then
            echo "error: Another process is currently listening on the CNI socket, exiting" 2>&1
            exit 1
          fi
        done

        # local environment overrides
        if [[ -f /etc/sysconfig/openshift-sdn ]]; then
          set -o allexport
          source /etc/sysconfig/openshift-sdn
          set +o allexport
        fi
        #BUG: cdc accidentally mounted /etc/sysconfig/openshift-sdn as DirectoryOrCreate; clean it up so we can ultimately mount /etc/sysconfig/openshift-sdn as FileOrCreate
        # Once this is released, then we can mount it properly
        if [[ -d /etc/sysconfig/openshift-sdn ]]; then
          rmdir /etc/sysconfig/openshift-sdn || true
        fi

        # configmap-based overrides
        if [[ -f /env/${K8S_NODE_NAME} ]]; then
          set -o allexport
          source /env/${K8S_NODE_NAME}
          set +o allexport
        fi

        # Take over network functions on the node
        rm -f /etc/cni/net.d/80-openshift-network.conf
        cp -f /opt/cni/bin/openshift-sdn /host-cni-bin/

        mtu_override_flag=
        if [[ -f /config/mtu.yaml ]]; then
          mtu_override_flag="--mtu-override /config/mtu.yaml"
        fi

        # Launch the network process
        exec /usr/bin/openshift-sdn-node \
          --node-name ${K8S_NODE_NAME} --node-ip ${K8S_NODE_IP} \
          --platform-type Azure \
          --proxy-config /config/kube-proxy-config.yaml \
          ${mtu_override_flag} \
          --v ${OPENSHIFT_SDN_LOG_LEVEL:-2}
      env:
      - name: KUBERNETES_SERVICE_PORT
        value: "6443"
      - name: KUBERNETES_SERVICE_HOST
        value: api-int.ocp4azu.dirtrab.cl
      - name: OPENSHIFT_DNS_DOMAIN
        value: cluster.local
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: K8S_NODE_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - rm
            - -f
            - /etc/cni/net.d/80-openshift-network.conf
            - /host-cni-bin/openshift-sdn
      name: sdn
      ports:
      - containerPort: 10256
        hostPort: 10256
        name: healthz
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - test
          - -f
          - /etc/cni/net.d/80-openshift-network.conf
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /config
        name: config
        readOnly: true
      - mountPath: /env
        name: env-overrides
      - mountPath: /var/run
        name: host-var-run
      - mountPath: /var/run/dbus/
        name: host-var-run-dbus
        readOnly: true
      - mountPath: /var/run/openvswitch/
        name: host-var-run-ovs
        readOnly: true
      - mountPath: /var/run/kubernetes/
        name: host-var-run-kubernetes
        readOnly: true
      - mountPath: /run/netns
        mountPropagation: HostToContainer
        name: host-run-netns
        readOnly: true
      - mountPath: /host/var/run/netns
        mountPropagation: HostToContainer
        name: host-var-run-netns
        readOnly: true
      - mountPath: /var/run/openshift-sdn
        name: host-var-run-openshift-sdn
      - mountPath: /host
        mountPropagation: HostToContainer
        name: host-slash
        readOnly: true
      - mountPath: /host-cni-bin
        name: host-cni-bin
      - mountPath: /etc/cni/net.d
        name: host-cni-conf
      - mountPath: /var/lib/cni/networks/openshift-sdn
        name: host-var-lib-cni-networks-openshift-sdn
      - mountPath: /lib/modules
        name: host-modules
        readOnly: true
      - mountPath: /etc/sysconfig
        name: etc-sysconfig
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-jfh4k
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail
        TLS_PK=/etc/pki/tls/metrics-certs/tls.key
        TLS_CERT=/etc/pki/tls/metrics-certs/tls.crt

        # As the secret mount is optional we must wait for the files to be present.
        # The service is created in monitor.yaml and this is created in sdn.yaml.
        # If it isn't created there is probably an issue so we want to crashloop.
        TS=$(date +%s)
        WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
        HAS_LOGGED_INFO=0

        log_missing_certs(){
            CUR_TS=$(date +%s)
            if [[ "${CUR_TS}" -gt "WARN_TS"  ]]; then
              echo $(date -Iseconds) WARN: sdn-metrics-certs not mounted after 20 minutes.
            elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
              echo $(date -Iseconds) INFO: sdn-metrics-certs not mounted. Waiting 20 minutes.
              HAS_LOGGED_INFO=1
            fi
        }

        while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
          log_missing_certs
          sleep 5
        done

        echo $(date -Iseconds) INFO: sdn-metrics-certs mounted, starting kube-rbac-proxy
        exec /usr/bin/kube-rbac-proxy \
          --logtostderr \
          --secure-listen-address=:9101 \
          --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
          --upstream=http://127.0.0.1:29101/ \
          --tls-private-key-file=${TLS_PK} \
          --tls-cert-file=${TLS_CERT}
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9101
        hostPort: 9101
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/tls/metrics-certs
        name: sdn-metrics-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-jfh4k
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        set -xe

        touch /var/run/add_iptables.sh
        chmod 0755 /var/run/add_iptables.sh
        cat <<'EOF' > /var/run/add_iptables.sh
        #!/bin/sh
        if [ -z "$3" ]
        then
             echo "Called with host address missing, ignore"
             exit 0
        fi
        echo "Adding ICMP drop rule for '$3' "
        if iptables -C AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        then
             echo "iptables already set for $3"
        else
             iptables -A AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        fi
        EOF

        echo "I$(date "+%m%d %H:%M:%S.%N") - drop-icmp - start drop-icmp ${K8S_NODE}"
        iptables -X AZURE_CHECK_ICMP_SOURCE || true
        iptables -N AZURE_CHECK_ICMP_SOURCE || true
        iptables -F AZURE_CHECK_ICMP_SOURCE
        iptables -D INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE || true
        iptables -I INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE
        iptables -N AZURE_ICMP_ACTION || true
        iptables -F AZURE_ICMP_ACTION
        iptables -A AZURE_ICMP_ACTION -j LOG
        iptables -A AZURE_ICMP_ACTION -j DROP
        /host/usr/bin/oc observe pods -n openshift-sdn -l app=sdn -a '{ .status.hostIP }' -- /var/run/add_iptables.sh
      env:
      - name: K8S_NODE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/bash
            - -c
            - echo drop-icmp done
      name: drop-icmp
      resources:
        requests:
          cpu: 5m
          memory: 20Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        name: host-slash
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-jfh4k
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    nodeName: ocp4azu-sj2sl-master-2
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: sdn
    serviceAccountName: sdn
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sdn-config
      name: config
    - configMap:
        defaultMode: 420
        name: env-overrides
        optional: true
      name: env-overrides
    - hostPath:
        path: /etc/sysconfig
        type: ""
      name: etc-sysconfig
    - hostPath:
        path: /lib/modules
        type: ""
      name: host-modules
    - hostPath:
        path: /var/run
        type: ""
      name: host-var-run
    - hostPath:
        path: /run/netns
        type: ""
      name: host-run-netns
    - hostPath:
        path: /var/run/netns
        type: ""
      name: host-var-run-netns
    - hostPath:
        path: /var/run/dbus
        type: ""
      name: host-var-run-dbus
    - hostPath:
        path: /var/run/openvswitch
        type: ""
      name: host-var-run-ovs
    - hostPath:
        path: /var/run/kubernetes
        type: ""
      name: host-var-run-kubernetes
    - hostPath:
        path: /var/run/openshift-sdn
        type: ""
      name: host-var-run-openshift-sdn
    - hostPath:
        path: /
        type: ""
      name: host-slash
    - hostPath:
        path: /var/lib/cni/bin
        type: ""
      name: host-cni-bin
    - hostPath:
        path: /var/run/multus/cni/net.d
        type: ""
      name: host-cni-conf
    - hostPath:
        path: /var/lib/cni/networks/openshift-sdn
        type: ""
      name: host-var-lib-cni-networks-openshift-sdn
    - name: sdn-metrics-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: sdn-metrics-certs
    - name: kube-api-access-jfh4k
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-05-04T21:39:44Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-05-11T18:26:23Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-05-11T18:26:23Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-05-04T21:39:44Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://ede99b0207afaeb649ecc891453226b86977cecb1333b05d19d60f5b7fadb973
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: drop-icmp
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2023-05-11T18:26:13Z"
    - containerID: cri-o://a3a516d6d897fe6b79d6cecd914ca1dd2402f4b3b90a3516042d64bea174b847
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2023-05-11T18:26:13Z"
    - containerID: cri-o://733ece53cd26f862e539a2570369bb24c3790d6718fee3fba4bb8f26a37bb6ff
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: sdn
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2023-05-11T18:26:13Z"
    hostIP: 10.80.80.7
    phase: Running
    podIP: 10.80.80.7
    podIPs:
    - ip: 10.80.80.7
    qosClass: Burstable
    startTime: "2023-05-04T21:39:44Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-05-17T18:14:31Z"
    generateName: sdn-
    labels:
      app: sdn
      component: network
      controller-revision-hash: 749f49c4cc
      openshift.io/component: network
      pod-template-generation: "1"
      type: infra
    name: sdn-lg286
    namespace: openshift-sdn
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sdn
      uid: 79c4ac3b-dde1-4470-a005-a221cb9e48d9
    resourceVersion: "460420433"
    uid: e5936909-4638-4aef-b7ca-718f393a15ca
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ocp4azu-sj2sl-infra-brazilsouth1-5zvnf
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail

        # if another process is listening on the cni-server socket, wait until it exits
        trap 'kill $(jobs -p); rm -f /etc/cni/net.d/80-openshift-network.conf ; exit 0' TERM
        retries=0
        while true; do
          if echo 'test' | socat - UNIX-CONNECT:/var/run/openshift-sdn/cniserver/socket &>/dev/null; then
            echo "warning: Another process is currently listening on the CNI socket, waiting 15s ..." 2>&1
            sleep 15 & wait
            (( retries += 1 ))
          else
            break
          fi
          if [[ "${retries}" -gt 40 ]]; then
            echo "error: Another process is currently listening on the CNI socket, exiting" 2>&1
            exit 1
          fi
        done

        # local environment overrides
        if [[ -f /etc/sysconfig/openshift-sdn ]]; then
          set -o allexport
          source /etc/sysconfig/openshift-sdn
          set +o allexport
        fi
        #BUG: cdc accidentally mounted /etc/sysconfig/openshift-sdn as DirectoryOrCreate; clean it up so we can ultimately mount /etc/sysconfig/openshift-sdn as FileOrCreate
        # Once this is released, then we can mount it properly
        if [[ -d /etc/sysconfig/openshift-sdn ]]; then
          rmdir /etc/sysconfig/openshift-sdn || true
        fi

        # configmap-based overrides
        if [[ -f /env/${K8S_NODE_NAME} ]]; then
          set -o allexport
          source /env/${K8S_NODE_NAME}
          set +o allexport
        fi

        # Take over network functions on the node
        rm -f /etc/cni/net.d/80-openshift-network.conf
        cp -f /opt/cni/bin/openshift-sdn /host-cni-bin/

        mtu_override_flag=
        if [[ -f /config/mtu.yaml ]]; then
          mtu_override_flag="--mtu-override /config/mtu.yaml"
        fi

        # Launch the network process
        exec /usr/bin/openshift-sdn-node \
          --node-name ${K8S_NODE_NAME} --node-ip ${K8S_NODE_IP} \
          --platform-type Azure \
          --proxy-config /config/kube-proxy-config.yaml \
          ${mtu_override_flag} \
          --v ${OPENSHIFT_SDN_LOG_LEVEL:-2}
      env:
      - name: KUBERNETES_SERVICE_PORT
        value: "6443"
      - name: KUBERNETES_SERVICE_HOST
        value: api-int.ocp4azu.dirtrab.cl
      - name: OPENSHIFT_DNS_DOMAIN
        value: cluster.local
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: K8S_NODE_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - rm
            - -f
            - /etc/cni/net.d/80-openshift-network.conf
            - /host-cni-bin/openshift-sdn
      name: sdn
      ports:
      - containerPort: 10256
        hostPort: 10256
        name: healthz
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - test
          - -f
          - /etc/cni/net.d/80-openshift-network.conf
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /config
        name: config
        readOnly: true
      - mountPath: /env
        name: env-overrides
      - mountPath: /var/run
        name: host-var-run
      - mountPath: /var/run/dbus/
        name: host-var-run-dbus
        readOnly: true
      - mountPath: /var/run/openvswitch/
        name: host-var-run-ovs
        readOnly: true
      - mountPath: /var/run/kubernetes/
        name: host-var-run-kubernetes
        readOnly: true
      - mountPath: /run/netns
        mountPropagation: HostToContainer
        name: host-run-netns
        readOnly: true
      - mountPath: /host/var/run/netns
        mountPropagation: HostToContainer
        name: host-var-run-netns
        readOnly: true
      - mountPath: /var/run/openshift-sdn
        name: host-var-run-openshift-sdn
      - mountPath: /host
        mountPropagation: HostToContainer
        name: host-slash
        readOnly: true
      - mountPath: /host-cni-bin
        name: host-cni-bin
      - mountPath: /etc/cni/net.d
        name: host-cni-conf
      - mountPath: /var/lib/cni/networks/openshift-sdn
        name: host-var-lib-cni-networks-openshift-sdn
      - mountPath: /lib/modules
        name: host-modules
        readOnly: true
      - mountPath: /etc/sysconfig
        name: etc-sysconfig
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-c29z8
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail
        TLS_PK=/etc/pki/tls/metrics-certs/tls.key
        TLS_CERT=/etc/pki/tls/metrics-certs/tls.crt

        # As the secret mount is optional we must wait for the files to be present.
        # The service is created in monitor.yaml and this is created in sdn.yaml.
        # If it isn't created there is probably an issue so we want to crashloop.
        TS=$(date +%s)
        WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
        HAS_LOGGED_INFO=0

        log_missing_certs(){
            CUR_TS=$(date +%s)
            if [[ "${CUR_TS}" -gt "WARN_TS"  ]]; then
              echo $(date -Iseconds) WARN: sdn-metrics-certs not mounted after 20 minutes.
            elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
              echo $(date -Iseconds) INFO: sdn-metrics-certs not mounted. Waiting 20 minutes.
              HAS_LOGGED_INFO=1
            fi
        }

        while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
          log_missing_certs
          sleep 5
        done

        echo $(date -Iseconds) INFO: sdn-metrics-certs mounted, starting kube-rbac-proxy
        exec /usr/bin/kube-rbac-proxy \
          --logtostderr \
          --secure-listen-address=:9101 \
          --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
          --upstream=http://127.0.0.1:29101/ \
          --tls-private-key-file=${TLS_PK} \
          --tls-cert-file=${TLS_CERT}
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9101
        hostPort: 9101
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/tls/metrics-certs
        name: sdn-metrics-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-c29z8
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        set -xe

        touch /var/run/add_iptables.sh
        chmod 0755 /var/run/add_iptables.sh
        cat <<'EOF' > /var/run/add_iptables.sh
        #!/bin/sh
        if [ -z "$3" ]
        then
             echo "Called with host address missing, ignore"
             exit 0
        fi
        echo "Adding ICMP drop rule for '$3' "
        if iptables -C AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        then
             echo "iptables already set for $3"
        else
             iptables -A AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        fi
        EOF

        echo "I$(date "+%m%d %H:%M:%S.%N") - drop-icmp - start drop-icmp ${K8S_NODE}"
        iptables -X AZURE_CHECK_ICMP_SOURCE || true
        iptables -N AZURE_CHECK_ICMP_SOURCE || true
        iptables -F AZURE_CHECK_ICMP_SOURCE
        iptables -D INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE || true
        iptables -I INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE
        iptables -N AZURE_ICMP_ACTION || true
        iptables -F AZURE_ICMP_ACTION
        iptables -A AZURE_ICMP_ACTION -j LOG
        iptables -A AZURE_ICMP_ACTION -j DROP
        /host/usr/bin/oc observe pods -n openshift-sdn -l app=sdn -a '{ .status.hostIP }' -- /var/run/add_iptables.sh
      env:
      - name: K8S_NODE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/bash
            - -c
            - echo drop-icmp done
      name: drop-icmp
      resources:
        requests:
          cpu: 5m
          memory: 20Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        name: host-slash
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-c29z8
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: sdn-dockercfg-46nvg
    nodeName: ocp4azu-sj2sl-infra-brazilsouth1-5zvnf
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: sdn
    serviceAccountName: sdn
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sdn-config
      name: config
    - configMap:
        defaultMode: 420
        name: env-overrides
        optional: true
      name: env-overrides
    - hostPath:
        path: /etc/sysconfig
        type: ""
      name: etc-sysconfig
    - hostPath:
        path: /lib/modules
        type: ""
      name: host-modules
    - hostPath:
        path: /var/run
        type: ""
      name: host-var-run
    - hostPath:
        path: /run/netns
        type: ""
      name: host-run-netns
    - hostPath:
        path: /var/run/netns
        type: ""
      name: host-var-run-netns
    - hostPath:
        path: /var/run/dbus
        type: ""
      name: host-var-run-dbus
    - hostPath:
        path: /var/run/openvswitch
        type: ""
      name: host-var-run-ovs
    - hostPath:
        path: /var/run/kubernetes
        type: ""
      name: host-var-run-kubernetes
    - hostPath:
        path: /var/run/openshift-sdn
        type: ""
      name: host-var-run-openshift-sdn
    - hostPath:
        path: /
        type: ""
      name: host-slash
    - hostPath:
        path: /var/lib/cni/bin
        type: ""
      name: host-cni-bin
    - hostPath:
        path: /var/run/multus/cni/net.d
        type: ""
      name: host-cni-conf
    - hostPath:
        path: /var/lib/cni/networks/openshift-sdn
        type: ""
      name: host-var-lib-cni-networks-openshift-sdn
    - name: sdn-metrics-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: sdn-metrics-certs
    - name: kube-api-access-c29z8
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-05-17T18:14:31Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-05-17T18:14:55Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-05-17T18:14:55Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-05-17T18:14:31Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://5dcdc8fc537558de64efcfa670d3891ad4c2f3a7b716542901824c48f3a5181d
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: drop-icmp
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-17T18:14:54Z"
    - containerID: cri-o://db6a6ba2468600e2af0cc28094acce31b95ebb89ba74cdafe692e94809e10938
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-17T18:14:54Z"
    - containerID: cri-o://98d9c5ed11fa125cc8d365d2ba5e11b2a458df1d93f0a994934f6787fd6ff0ff
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: sdn
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-17T18:14:49Z"
    hostIP: 10.80.80.11
    phase: Running
    podIP: 10.80.80.11
    podIPs:
    - ip: 10.80.80.11
    qosClass: Burstable
    startTime: "2023-05-17T18:14:31Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-05-25T13:26:47Z"
    generateName: sdn-
    labels:
      app: sdn
      component: network
      controller-revision-hash: 749f49c4cc
      openshift.io/component: network
      pod-template-generation: "1"
      type: infra
    name: sdn-nz8f8
    namespace: openshift-sdn
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sdn
      uid: 79c4ac3b-dde1-4470-a005-a221cb9e48d9
    resourceVersion: "472917994"
    uid: 11d3d9af-fe31-4c51-8457-63f88cae5f4a
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ocp4azu-sj2sl-worker-noprod-qa-brazilsouth1-2s77x
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail

        # if another process is listening on the cni-server socket, wait until it exits
        trap 'kill $(jobs -p); rm -f /etc/cni/net.d/80-openshift-network.conf ; exit 0' TERM
        retries=0
        while true; do
          if echo 'test' | socat - UNIX-CONNECT:/var/run/openshift-sdn/cniserver/socket &>/dev/null; then
            echo "warning: Another process is currently listening on the CNI socket, waiting 15s ..." 2>&1
            sleep 15 & wait
            (( retries += 1 ))
          else
            break
          fi
          if [[ "${retries}" -gt 40 ]]; then
            echo "error: Another process is currently listening on the CNI socket, exiting" 2>&1
            exit 1
          fi
        done

        # local environment overrides
        if [[ -f /etc/sysconfig/openshift-sdn ]]; then
          set -o allexport
          source /etc/sysconfig/openshift-sdn
          set +o allexport
        fi
        #BUG: cdc accidentally mounted /etc/sysconfig/openshift-sdn as DirectoryOrCreate; clean it up so we can ultimately mount /etc/sysconfig/openshift-sdn as FileOrCreate
        # Once this is released, then we can mount it properly
        if [[ -d /etc/sysconfig/openshift-sdn ]]; then
          rmdir /etc/sysconfig/openshift-sdn || true
        fi

        # configmap-based overrides
        if [[ -f /env/${K8S_NODE_NAME} ]]; then
          set -o allexport
          source /env/${K8S_NODE_NAME}
          set +o allexport
        fi

        # Take over network functions on the node
        rm -f /etc/cni/net.d/80-openshift-network.conf
        cp -f /opt/cni/bin/openshift-sdn /host-cni-bin/

        mtu_override_flag=
        if [[ -f /config/mtu.yaml ]]; then
          mtu_override_flag="--mtu-override /config/mtu.yaml"
        fi

        # Launch the network process
        exec /usr/bin/openshift-sdn-node \
          --node-name ${K8S_NODE_NAME} --node-ip ${K8S_NODE_IP} \
          --platform-type Azure \
          --proxy-config /config/kube-proxy-config.yaml \
          ${mtu_override_flag} \
          --v ${OPENSHIFT_SDN_LOG_LEVEL:-2}
      env:
      - name: KUBERNETES_SERVICE_PORT
        value: "6443"
      - name: KUBERNETES_SERVICE_HOST
        value: api-int.ocp4azu.dirtrab.cl
      - name: OPENSHIFT_DNS_DOMAIN
        value: cluster.local
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: K8S_NODE_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - rm
            - -f
            - /etc/cni/net.d/80-openshift-network.conf
            - /host-cni-bin/openshift-sdn
      name: sdn
      ports:
      - containerPort: 10256
        hostPort: 10256
        name: healthz
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - test
          - -f
          - /etc/cni/net.d/80-openshift-network.conf
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /config
        name: config
        readOnly: true
      - mountPath: /env
        name: env-overrides
      - mountPath: /var/run
        name: host-var-run
      - mountPath: /var/run/dbus/
        name: host-var-run-dbus
        readOnly: true
      - mountPath: /var/run/openvswitch/
        name: host-var-run-ovs
        readOnly: true
      - mountPath: /var/run/kubernetes/
        name: host-var-run-kubernetes
        readOnly: true
      - mountPath: /run/netns
        mountPropagation: HostToContainer
        name: host-run-netns
        readOnly: true
      - mountPath: /host/var/run/netns
        mountPropagation: HostToContainer
        name: host-var-run-netns
        readOnly: true
      - mountPath: /var/run/openshift-sdn
        name: host-var-run-openshift-sdn
      - mountPath: /host
        mountPropagation: HostToContainer
        name: host-slash
        readOnly: true
      - mountPath: /host-cni-bin
        name: host-cni-bin
      - mountPath: /etc/cni/net.d
        name: host-cni-conf
      - mountPath: /var/lib/cni/networks/openshift-sdn
        name: host-var-lib-cni-networks-openshift-sdn
      - mountPath: /lib/modules
        name: host-modules
        readOnly: true
      - mountPath: /etc/sysconfig
        name: etc-sysconfig
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-df2d2
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail
        TLS_PK=/etc/pki/tls/metrics-certs/tls.key
        TLS_CERT=/etc/pki/tls/metrics-certs/tls.crt

        # As the secret mount is optional we must wait for the files to be present.
        # The service is created in monitor.yaml and this is created in sdn.yaml.
        # If it isn't created there is probably an issue so we want to crashloop.
        TS=$(date +%s)
        WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
        HAS_LOGGED_INFO=0

        log_missing_certs(){
            CUR_TS=$(date +%s)
            if [[ "${CUR_TS}" -gt "WARN_TS"  ]]; then
              echo $(date -Iseconds) WARN: sdn-metrics-certs not mounted after 20 minutes.
            elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
              echo $(date -Iseconds) INFO: sdn-metrics-certs not mounted. Waiting 20 minutes.
              HAS_LOGGED_INFO=1
            fi
        }

        while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
          log_missing_certs
          sleep 5
        done

        echo $(date -Iseconds) INFO: sdn-metrics-certs mounted, starting kube-rbac-proxy
        exec /usr/bin/kube-rbac-proxy \
          --logtostderr \
          --secure-listen-address=:9101 \
          --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
          --upstream=http://127.0.0.1:29101/ \
          --tls-private-key-file=${TLS_PK} \
          --tls-cert-file=${TLS_CERT}
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9101
        hostPort: 9101
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/tls/metrics-certs
        name: sdn-metrics-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-df2d2
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        set -xe

        touch /var/run/add_iptables.sh
        chmod 0755 /var/run/add_iptables.sh
        cat <<'EOF' > /var/run/add_iptables.sh
        #!/bin/sh
        if [ -z "$3" ]
        then
             echo "Called with host address missing, ignore"
             exit 0
        fi
        echo "Adding ICMP drop rule for '$3' "
        if iptables -C AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        then
             echo "iptables already set for $3"
        else
             iptables -A AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        fi
        EOF

        echo "I$(date "+%m%d %H:%M:%S.%N") - drop-icmp - start drop-icmp ${K8S_NODE}"
        iptables -X AZURE_CHECK_ICMP_SOURCE || true
        iptables -N AZURE_CHECK_ICMP_SOURCE || true
        iptables -F AZURE_CHECK_ICMP_SOURCE
        iptables -D INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE || true
        iptables -I INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE
        iptables -N AZURE_ICMP_ACTION || true
        iptables -F AZURE_ICMP_ACTION
        iptables -A AZURE_ICMP_ACTION -j LOG
        iptables -A AZURE_ICMP_ACTION -j DROP
        /host/usr/bin/oc observe pods -n openshift-sdn -l app=sdn -a '{ .status.hostIP }' -- /var/run/add_iptables.sh
      env:
      - name: K8S_NODE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/bash
            - -c
            - echo drop-icmp done
      name: drop-icmp
      resources:
        requests:
          cpu: 5m
          memory: 20Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        name: host-slash
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-df2d2
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: sdn-dockercfg-46nvg
    nodeName: ocp4azu-sj2sl-worker-noprod-qa-brazilsouth1-2s77x
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: sdn
    serviceAccountName: sdn
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sdn-config
      name: config
    - configMap:
        defaultMode: 420
        name: env-overrides
        optional: true
      name: env-overrides
    - hostPath:
        path: /etc/sysconfig
        type: ""
      name: etc-sysconfig
    - hostPath:
        path: /lib/modules
        type: ""
      name: host-modules
    - hostPath:
        path: /var/run
        type: ""
      name: host-var-run
    - hostPath:
        path: /run/netns
        type: ""
      name: host-run-netns
    - hostPath:
        path: /var/run/netns
        type: ""
      name: host-var-run-netns
    - hostPath:
        path: /var/run/dbus
        type: ""
      name: host-var-run-dbus
    - hostPath:
        path: /var/run/openvswitch
        type: ""
      name: host-var-run-ovs
    - hostPath:
        path: /var/run/kubernetes
        type: ""
      name: host-var-run-kubernetes
    - hostPath:
        path: /var/run/openshift-sdn
        type: ""
      name: host-var-run-openshift-sdn
    - hostPath:
        path: /
        type: ""
      name: host-slash
    - hostPath:
        path: /var/lib/cni/bin
        type: ""
      name: host-cni-bin
    - hostPath:
        path: /var/run/multus/cni/net.d
        type: ""
      name: host-cni-conf
    - hostPath:
        path: /var/lib/cni/networks/openshift-sdn
        type: ""
      name: host-var-lib-cni-networks-openshift-sdn
    - name: sdn-metrics-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: sdn-metrics-certs
    - name: kube-api-access-df2d2
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T13:26:47Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T13:27:22Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T13:27:22Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T13:26:47Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://cc274f7518ba672f6a71b81f9bc959f84623dbd83f8dce281031c81485595936
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: drop-icmp
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T13:27:21Z"
    - containerID: cri-o://33fa182c9f0c15d10f06629c70042a3315664669a24653c4408b21cad2a1ae41
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T13:27:21Z"
    - containerID: cri-o://cc88f7a93c0bd0debd2efac60619f6f97b9e838096dcb86e4e9e4f314f908a39
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: sdn
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T13:27:07Z"
    hostIP: 10.80.80.28
    phase: Running
    podIP: 10.80.80.28
    podIPs:
    - ip: 10.80.80.28
    qosClass: Burstable
    startTime: "2023-05-25T13:26:47Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-05-25T14:41:57Z"
    generateName: sdn-
    labels:
      app: sdn
      component: network
      controller-revision-hash: 749f49c4cc
      openshift.io/component: network
      pod-template-generation: "1"
      type: infra
    name: sdn-pbczl
    namespace: openshift-sdn
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sdn
      uid: 79c4ac3b-dde1-4470-a005-a221cb9e48d9
    resourceVersion: "476624516"
    uid: 14db56e6-e82f-4e25-9a64-795f7381d6cc
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ocp4azu-sj2sl-worker-noprod-dev-brazilsouth2-4dm6s
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail

        # if another process is listening on the cni-server socket, wait until it exits
        trap 'kill $(jobs -p); rm -f /etc/cni/net.d/80-openshift-network.conf ; exit 0' TERM
        retries=0
        while true; do
          if echo 'test' | socat - UNIX-CONNECT:/var/run/openshift-sdn/cniserver/socket &>/dev/null; then
            echo "warning: Another process is currently listening on the CNI socket, waiting 15s ..." 2>&1
            sleep 15 & wait
            (( retries += 1 ))
          else
            break
          fi
          if [[ "${retries}" -gt 40 ]]; then
            echo "error: Another process is currently listening on the CNI socket, exiting" 2>&1
            exit 1
          fi
        done

        # local environment overrides
        if [[ -f /etc/sysconfig/openshift-sdn ]]; then
          set -o allexport
          source /etc/sysconfig/openshift-sdn
          set +o allexport
        fi
        #BUG: cdc accidentally mounted /etc/sysconfig/openshift-sdn as DirectoryOrCreate; clean it up so we can ultimately mount /etc/sysconfig/openshift-sdn as FileOrCreate
        # Once this is released, then we can mount it properly
        if [[ -d /etc/sysconfig/openshift-sdn ]]; then
          rmdir /etc/sysconfig/openshift-sdn || true
        fi

        # configmap-based overrides
        if [[ -f /env/${K8S_NODE_NAME} ]]; then
          set -o allexport
          source /env/${K8S_NODE_NAME}
          set +o allexport
        fi

        # Take over network functions on the node
        rm -f /etc/cni/net.d/80-openshift-network.conf
        cp -f /opt/cni/bin/openshift-sdn /host-cni-bin/

        mtu_override_flag=
        if [[ -f /config/mtu.yaml ]]; then
          mtu_override_flag="--mtu-override /config/mtu.yaml"
        fi

        # Launch the network process
        exec /usr/bin/openshift-sdn-node \
          --node-name ${K8S_NODE_NAME} --node-ip ${K8S_NODE_IP} \
          --platform-type Azure \
          --proxy-config /config/kube-proxy-config.yaml \
          ${mtu_override_flag} \
          --v ${OPENSHIFT_SDN_LOG_LEVEL:-2}
      env:
      - name: KUBERNETES_SERVICE_PORT
        value: "6443"
      - name: KUBERNETES_SERVICE_HOST
        value: api-int.ocp4azu.dirtrab.cl
      - name: OPENSHIFT_DNS_DOMAIN
        value: cluster.local
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: K8S_NODE_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - rm
            - -f
            - /etc/cni/net.d/80-openshift-network.conf
            - /host-cni-bin/openshift-sdn
      name: sdn
      ports:
      - containerPort: 10256
        hostPort: 10256
        name: healthz
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - test
          - -f
          - /etc/cni/net.d/80-openshift-network.conf
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /config
        name: config
        readOnly: true
      - mountPath: /env
        name: env-overrides
      - mountPath: /var/run
        name: host-var-run
      - mountPath: /var/run/dbus/
        name: host-var-run-dbus
        readOnly: true
      - mountPath: /var/run/openvswitch/
        name: host-var-run-ovs
        readOnly: true
      - mountPath: /var/run/kubernetes/
        name: host-var-run-kubernetes
        readOnly: true
      - mountPath: /run/netns
        mountPropagation: HostToContainer
        name: host-run-netns
        readOnly: true
      - mountPath: /host/var/run/netns
        mountPropagation: HostToContainer
        name: host-var-run-netns
        readOnly: true
      - mountPath: /var/run/openshift-sdn
        name: host-var-run-openshift-sdn
      - mountPath: /host
        mountPropagation: HostToContainer
        name: host-slash
        readOnly: true
      - mountPath: /host-cni-bin
        name: host-cni-bin
      - mountPath: /etc/cni/net.d
        name: host-cni-conf
      - mountPath: /var/lib/cni/networks/openshift-sdn
        name: host-var-lib-cni-networks-openshift-sdn
      - mountPath: /lib/modules
        name: host-modules
        readOnly: true
      - mountPath: /etc/sysconfig
        name: etc-sysconfig
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rfj2b
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail
        TLS_PK=/etc/pki/tls/metrics-certs/tls.key
        TLS_CERT=/etc/pki/tls/metrics-certs/tls.crt

        # As the secret mount is optional we must wait for the files to be present.
        # The service is created in monitor.yaml and this is created in sdn.yaml.
        # If it isn't created there is probably an issue so we want to crashloop.
        TS=$(date +%s)
        WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
        HAS_LOGGED_INFO=0

        log_missing_certs(){
            CUR_TS=$(date +%s)
            if [[ "${CUR_TS}" -gt "WARN_TS"  ]]; then
              echo $(date -Iseconds) WARN: sdn-metrics-certs not mounted after 20 minutes.
            elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
              echo $(date -Iseconds) INFO: sdn-metrics-certs not mounted. Waiting 20 minutes.
              HAS_LOGGED_INFO=1
            fi
        }

        while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
          log_missing_certs
          sleep 5
        done

        echo $(date -Iseconds) INFO: sdn-metrics-certs mounted, starting kube-rbac-proxy
        exec /usr/bin/kube-rbac-proxy \
          --logtostderr \
          --secure-listen-address=:9101 \
          --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
          --upstream=http://127.0.0.1:29101/ \
          --tls-private-key-file=${TLS_PK} \
          --tls-cert-file=${TLS_CERT}
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9101
        hostPort: 9101
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/tls/metrics-certs
        name: sdn-metrics-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rfj2b
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        set -xe

        touch /var/run/add_iptables.sh
        chmod 0755 /var/run/add_iptables.sh
        cat <<'EOF' > /var/run/add_iptables.sh
        #!/bin/sh
        if [ -z "$3" ]
        then
             echo "Called with host address missing, ignore"
             exit 0
        fi
        echo "Adding ICMP drop rule for '$3' "
        if iptables -C AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        then
             echo "iptables already set for $3"
        else
             iptables -A AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        fi
        EOF

        echo "I$(date "+%m%d %H:%M:%S.%N") - drop-icmp - start drop-icmp ${K8S_NODE}"
        iptables -X AZURE_CHECK_ICMP_SOURCE || true
        iptables -N AZURE_CHECK_ICMP_SOURCE || true
        iptables -F AZURE_CHECK_ICMP_SOURCE
        iptables -D INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE || true
        iptables -I INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE
        iptables -N AZURE_ICMP_ACTION || true
        iptables -F AZURE_ICMP_ACTION
        iptables -A AZURE_ICMP_ACTION -j LOG
        iptables -A AZURE_ICMP_ACTION -j DROP
        /host/usr/bin/oc observe pods -n openshift-sdn -l app=sdn -a '{ .status.hostIP }' -- /var/run/add_iptables.sh
      env:
      - name: K8S_NODE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/bash
            - -c
            - echo drop-icmp done
      name: drop-icmp
      resources:
        requests:
          cpu: 5m
          memory: 20Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        name: host-slash
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rfj2b
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: sdn-dockercfg-46nvg
    nodeName: ocp4azu-sj2sl-worker-noprod-dev-brazilsouth2-4dm6s
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: sdn
    serviceAccountName: sdn
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sdn-config
      name: config
    - configMap:
        defaultMode: 420
        name: env-overrides
        optional: true
      name: env-overrides
    - hostPath:
        path: /etc/sysconfig
        type: ""
      name: etc-sysconfig
    - hostPath:
        path: /lib/modules
        type: ""
      name: host-modules
    - hostPath:
        path: /var/run
        type: ""
      name: host-var-run
    - hostPath:
        path: /run/netns
        type: ""
      name: host-run-netns
    - hostPath:
        path: /var/run/netns
        type: ""
      name: host-var-run-netns
    - hostPath:
        path: /var/run/dbus
        type: ""
      name: host-var-run-dbus
    - hostPath:
        path: /var/run/openvswitch
        type: ""
      name: host-var-run-ovs
    - hostPath:
        path: /var/run/kubernetes
        type: ""
      name: host-var-run-kubernetes
    - hostPath:
        path: /var/run/openshift-sdn
        type: ""
      name: host-var-run-openshift-sdn
    - hostPath:
        path: /
        type: ""
      name: host-slash
    - hostPath:
        path: /var/lib/cni/bin
        type: ""
      name: host-cni-bin
    - hostPath:
        path: /var/run/multus/cni/net.d
        type: ""
      name: host-cni-conf
    - hostPath:
        path: /var/lib/cni/networks/openshift-sdn
        type: ""
      name: host-var-lib-cni-networks-openshift-sdn
    - name: sdn-metrics-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: sdn-metrics-certs
    - name: kube-api-access-rfj2b
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T14:41:58Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-05-02T14:26:41Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-05-02T14:26:41Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T14:41:57Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://1ffe4a92579b4f31539b61428377049b0c13aa87cd800adea7cd243b3cfd3377
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: drop-icmp
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-05-02T14:26:40Z"
    - containerID: cri-o://40957eccad87090ec483ccf60948d4fbd4fc9cb55853e4da13f44cfbea9e0fbc
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-05-02T14:26:36Z"
    - containerID: cri-o://12d5b314cfd54462afa206f0990bc2f15461d07960055a64e3e1186b7289f531
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: sdn
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-05-02T14:24:43Z"
    hostIP: 10.80.80.9
    phase: Running
    podIP: 10.80.80.9
    podIPs:
    - ip: 10.80.80.9
    qosClass: Burstable
    startTime: "2023-05-25T14:41:58Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-05-04T21:39:44Z"
    generateName: sdn-
    labels:
      app: sdn
      component: network
      controller-revision-hash: 749f49c4cc
      openshift.io/component: network
      pod-template-generation: "1"
      type: infra
    name: sdn-q25hs
    namespace: openshift-sdn
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sdn
      uid: 79c4ac3b-dde1-4470-a005-a221cb9e48d9
    resourceVersion: "114617619"
    uid: 38cbde1c-a89c-44fc-93e2-7214b3580e77
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ocp4azu-sj2sl-master-1
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail

        # if another process is listening on the cni-server socket, wait until it exits
        trap 'kill $(jobs -p); rm -f /etc/cni/net.d/80-openshift-network.conf ; exit 0' TERM
        retries=0
        while true; do
          if echo 'test' | socat - UNIX-CONNECT:/var/run/openshift-sdn/cniserver/socket &>/dev/null; then
            echo "warning: Another process is currently listening on the CNI socket, waiting 15s ..." 2>&1
            sleep 15 & wait
            (( retries += 1 ))
          else
            break
          fi
          if [[ "${retries}" -gt 40 ]]; then
            echo "error: Another process is currently listening on the CNI socket, exiting" 2>&1
            exit 1
          fi
        done

        # local environment overrides
        if [[ -f /etc/sysconfig/openshift-sdn ]]; then
          set -o allexport
          source /etc/sysconfig/openshift-sdn
          set +o allexport
        fi
        #BUG: cdc accidentally mounted /etc/sysconfig/openshift-sdn as DirectoryOrCreate; clean it up so we can ultimately mount /etc/sysconfig/openshift-sdn as FileOrCreate
        # Once this is released, then we can mount it properly
        if [[ -d /etc/sysconfig/openshift-sdn ]]; then
          rmdir /etc/sysconfig/openshift-sdn || true
        fi

        # configmap-based overrides
        if [[ -f /env/${K8S_NODE_NAME} ]]; then
          set -o allexport
          source /env/${K8S_NODE_NAME}
          set +o allexport
        fi

        # Take over network functions on the node
        rm -f /etc/cni/net.d/80-openshift-network.conf
        cp -f /opt/cni/bin/openshift-sdn /host-cni-bin/

        mtu_override_flag=
        if [[ -f /config/mtu.yaml ]]; then
          mtu_override_flag="--mtu-override /config/mtu.yaml"
        fi

        # Launch the network process
        exec /usr/bin/openshift-sdn-node \
          --node-name ${K8S_NODE_NAME} --node-ip ${K8S_NODE_IP} \
          --platform-type Azure \
          --proxy-config /config/kube-proxy-config.yaml \
          ${mtu_override_flag} \
          --v ${OPENSHIFT_SDN_LOG_LEVEL:-2}
      env:
      - name: KUBERNETES_SERVICE_PORT
        value: "6443"
      - name: KUBERNETES_SERVICE_HOST
        value: api-int.ocp4azu.dirtrab.cl
      - name: OPENSHIFT_DNS_DOMAIN
        value: cluster.local
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: K8S_NODE_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - rm
            - -f
            - /etc/cni/net.d/80-openshift-network.conf
            - /host-cni-bin/openshift-sdn
      name: sdn
      ports:
      - containerPort: 10256
        hostPort: 10256
        name: healthz
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - test
          - -f
          - /etc/cni/net.d/80-openshift-network.conf
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /config
        name: config
        readOnly: true
      - mountPath: /env
        name: env-overrides
      - mountPath: /var/run
        name: host-var-run
      - mountPath: /var/run/dbus/
        name: host-var-run-dbus
        readOnly: true
      - mountPath: /var/run/openvswitch/
        name: host-var-run-ovs
        readOnly: true
      - mountPath: /var/run/kubernetes/
        name: host-var-run-kubernetes
        readOnly: true
      - mountPath: /run/netns
        mountPropagation: HostToContainer
        name: host-run-netns
        readOnly: true
      - mountPath: /host/var/run/netns
        mountPropagation: HostToContainer
        name: host-var-run-netns
        readOnly: true
      - mountPath: /var/run/openshift-sdn
        name: host-var-run-openshift-sdn
      - mountPath: /host
        mountPropagation: HostToContainer
        name: host-slash
        readOnly: true
      - mountPath: /host-cni-bin
        name: host-cni-bin
      - mountPath: /etc/cni/net.d
        name: host-cni-conf
      - mountPath: /var/lib/cni/networks/openshift-sdn
        name: host-var-lib-cni-networks-openshift-sdn
      - mountPath: /lib/modules
        name: host-modules
        readOnly: true
      - mountPath: /etc/sysconfig
        name: etc-sysconfig
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-f6bwr
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail
        TLS_PK=/etc/pki/tls/metrics-certs/tls.key
        TLS_CERT=/etc/pki/tls/metrics-certs/tls.crt

        # As the secret mount is optional we must wait for the files to be present.
        # The service is created in monitor.yaml and this is created in sdn.yaml.
        # If it isn't created there is probably an issue so we want to crashloop.
        TS=$(date +%s)
        WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
        HAS_LOGGED_INFO=0

        log_missing_certs(){
            CUR_TS=$(date +%s)
            if [[ "${CUR_TS}" -gt "WARN_TS"  ]]; then
              echo $(date -Iseconds) WARN: sdn-metrics-certs not mounted after 20 minutes.
            elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
              echo $(date -Iseconds) INFO: sdn-metrics-certs not mounted. Waiting 20 minutes.
              HAS_LOGGED_INFO=1
            fi
        }

        while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
          log_missing_certs
          sleep 5
        done

        echo $(date -Iseconds) INFO: sdn-metrics-certs mounted, starting kube-rbac-proxy
        exec /usr/bin/kube-rbac-proxy \
          --logtostderr \
          --secure-listen-address=:9101 \
          --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
          --upstream=http://127.0.0.1:29101/ \
          --tls-private-key-file=${TLS_PK} \
          --tls-cert-file=${TLS_CERT}
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9101
        hostPort: 9101
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/tls/metrics-certs
        name: sdn-metrics-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-f6bwr
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        set -xe

        touch /var/run/add_iptables.sh
        chmod 0755 /var/run/add_iptables.sh
        cat <<'EOF' > /var/run/add_iptables.sh
        #!/bin/sh
        if [ -z "$3" ]
        then
             echo "Called with host address missing, ignore"
             exit 0
        fi
        echo "Adding ICMP drop rule for '$3' "
        if iptables -C AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        then
             echo "iptables already set for $3"
        else
             iptables -A AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        fi
        EOF

        echo "I$(date "+%m%d %H:%M:%S.%N") - drop-icmp - start drop-icmp ${K8S_NODE}"
        iptables -X AZURE_CHECK_ICMP_SOURCE || true
        iptables -N AZURE_CHECK_ICMP_SOURCE || true
        iptables -F AZURE_CHECK_ICMP_SOURCE
        iptables -D INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE || true
        iptables -I INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE
        iptables -N AZURE_ICMP_ACTION || true
        iptables -F AZURE_ICMP_ACTION
        iptables -A AZURE_ICMP_ACTION -j LOG
        iptables -A AZURE_ICMP_ACTION -j DROP
        /host/usr/bin/oc observe pods -n openshift-sdn -l app=sdn -a '{ .status.hostIP }' -- /var/run/add_iptables.sh
      env:
      - name: K8S_NODE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/bash
            - -c
            - echo drop-icmp done
      name: drop-icmp
      resources:
        requests:
          cpu: 5m
          memory: 20Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        name: host-slash
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-f6bwr
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    nodeName: ocp4azu-sj2sl-master-1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: sdn
    serviceAccountName: sdn
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sdn-config
      name: config
    - configMap:
        defaultMode: 420
        name: env-overrides
        optional: true
      name: env-overrides
    - hostPath:
        path: /etc/sysconfig
        type: ""
      name: etc-sysconfig
    - hostPath:
        path: /lib/modules
        type: ""
      name: host-modules
    - hostPath:
        path: /var/run
        type: ""
      name: host-var-run
    - hostPath:
        path: /run/netns
        type: ""
      name: host-run-netns
    - hostPath:
        path: /var/run/netns
        type: ""
      name: host-var-run-netns
    - hostPath:
        path: /var/run/dbus
        type: ""
      name: host-var-run-dbus
    - hostPath:
        path: /var/run/openvswitch
        type: ""
      name: host-var-run-ovs
    - hostPath:
        path: /var/run/kubernetes
        type: ""
      name: host-var-run-kubernetes
    - hostPath:
        path: /var/run/openshift-sdn
        type: ""
      name: host-var-run-openshift-sdn
    - hostPath:
        path: /
        type: ""
      name: host-slash
    - hostPath:
        path: /var/lib/cni/bin
        type: ""
      name: host-cni-bin
    - hostPath:
        path: /var/run/multus/cni/net.d
        type: ""
      name: host-cni-conf
    - hostPath:
        path: /var/lib/cni/networks/openshift-sdn
        type: ""
      name: host-var-lib-cni-networks-openshift-sdn
    - name: sdn-metrics-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: sdn-metrics-certs
    - name: kube-api-access-f6bwr
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-05-04T21:39:44Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-05-11T18:26:21Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-05-11T18:26:21Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-05-04T21:39:44Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://5c28ee01e3c06a44ddc6dae86ccd4b4410d75d08baa4bdf3e6997a55c7278887
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: drop-icmp
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2023-05-11T18:26:18Z"
    - containerID: cri-o://4eec1096c57b63516e587d4b11a13d9296df051575087267a81b19814c890d65
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2023-05-11T18:26:17Z"
    - containerID: cri-o://01d0be0d66f7dc2c303d631633b67c674ddd321aab3b82db7c55709a0a5ebf15
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: sdn
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2023-05-11T18:26:16Z"
    hostIP: 10.80.80.8
    phase: Running
    podIP: 10.80.80.8
    podIPs:
    - ip: 10.80.80.8
    qosClass: Burstable
    startTime: "2023-05-04T21:39:44Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-05-25T13:31:43Z"
    generateName: sdn-
    labels:
      app: sdn
      component: network
      controller-revision-hash: 749f49c4cc
      openshift.io/component: network
      pod-template-generation: "1"
      type: infra
    name: sdn-rcsxb
    namespace: openshift-sdn
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sdn
      uid: 79c4ac3b-dde1-4470-a005-a221cb9e48d9
    resourceVersion: "467404240"
    uid: 82841be8-a984-42d6-8c0f-93226595e857
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ocp4azu-sj2sl-worker-noprod-qa-brazilsouth2-rglbf
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail

        # if another process is listening on the cni-server socket, wait until it exits
        trap 'kill $(jobs -p); rm -f /etc/cni/net.d/80-openshift-network.conf ; exit 0' TERM
        retries=0
        while true; do
          if echo 'test' | socat - UNIX-CONNECT:/var/run/openshift-sdn/cniserver/socket &>/dev/null; then
            echo "warning: Another process is currently listening on the CNI socket, waiting 15s ..." 2>&1
            sleep 15 & wait
            (( retries += 1 ))
          else
            break
          fi
          if [[ "${retries}" -gt 40 ]]; then
            echo "error: Another process is currently listening on the CNI socket, exiting" 2>&1
            exit 1
          fi
        done

        # local environment overrides
        if [[ -f /etc/sysconfig/openshift-sdn ]]; then
          set -o allexport
          source /etc/sysconfig/openshift-sdn
          set +o allexport
        fi
        #BUG: cdc accidentally mounted /etc/sysconfig/openshift-sdn as DirectoryOrCreate; clean it up so we can ultimately mount /etc/sysconfig/openshift-sdn as FileOrCreate
        # Once this is released, then we can mount it properly
        if [[ -d /etc/sysconfig/openshift-sdn ]]; then
          rmdir /etc/sysconfig/openshift-sdn || true
        fi

        # configmap-based overrides
        if [[ -f /env/${K8S_NODE_NAME} ]]; then
          set -o allexport
          source /env/${K8S_NODE_NAME}
          set +o allexport
        fi

        # Take over network functions on the node
        rm -f /etc/cni/net.d/80-openshift-network.conf
        cp -f /opt/cni/bin/openshift-sdn /host-cni-bin/

        mtu_override_flag=
        if [[ -f /config/mtu.yaml ]]; then
          mtu_override_flag="--mtu-override /config/mtu.yaml"
        fi

        # Launch the network process
        exec /usr/bin/openshift-sdn-node \
          --node-name ${K8S_NODE_NAME} --node-ip ${K8S_NODE_IP} \
          --platform-type Azure \
          --proxy-config /config/kube-proxy-config.yaml \
          ${mtu_override_flag} \
          --v ${OPENSHIFT_SDN_LOG_LEVEL:-2}
      env:
      - name: KUBERNETES_SERVICE_PORT
        value: "6443"
      - name: KUBERNETES_SERVICE_HOST
        value: api-int.ocp4azu.dirtrab.cl
      - name: OPENSHIFT_DNS_DOMAIN
        value: cluster.local
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: K8S_NODE_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - rm
            - -f
            - /etc/cni/net.d/80-openshift-network.conf
            - /host-cni-bin/openshift-sdn
      name: sdn
      ports:
      - containerPort: 10256
        hostPort: 10256
        name: healthz
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - test
          - -f
          - /etc/cni/net.d/80-openshift-network.conf
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /config
        name: config
        readOnly: true
      - mountPath: /env
        name: env-overrides
      - mountPath: /var/run
        name: host-var-run
      - mountPath: /var/run/dbus/
        name: host-var-run-dbus
        readOnly: true
      - mountPath: /var/run/openvswitch/
        name: host-var-run-ovs
        readOnly: true
      - mountPath: /var/run/kubernetes/
        name: host-var-run-kubernetes
        readOnly: true
      - mountPath: /run/netns
        mountPropagation: HostToContainer
        name: host-run-netns
        readOnly: true
      - mountPath: /host/var/run/netns
        mountPropagation: HostToContainer
        name: host-var-run-netns
        readOnly: true
      - mountPath: /var/run/openshift-sdn
        name: host-var-run-openshift-sdn
      - mountPath: /host
        mountPropagation: HostToContainer
        name: host-slash
        readOnly: true
      - mountPath: /host-cni-bin
        name: host-cni-bin
      - mountPath: /etc/cni/net.d
        name: host-cni-conf
      - mountPath: /var/lib/cni/networks/openshift-sdn
        name: host-var-lib-cni-networks-openshift-sdn
      - mountPath: /lib/modules
        name: host-modules
        readOnly: true
      - mountPath: /etc/sysconfig
        name: etc-sysconfig
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pk9zb
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail
        TLS_PK=/etc/pki/tls/metrics-certs/tls.key
        TLS_CERT=/etc/pki/tls/metrics-certs/tls.crt

        # As the secret mount is optional we must wait for the files to be present.
        # The service is created in monitor.yaml and this is created in sdn.yaml.
        # If it isn't created there is probably an issue so we want to crashloop.
        TS=$(date +%s)
        WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
        HAS_LOGGED_INFO=0

        log_missing_certs(){
            CUR_TS=$(date +%s)
            if [[ "${CUR_TS}" -gt "WARN_TS"  ]]; then
              echo $(date -Iseconds) WARN: sdn-metrics-certs not mounted after 20 minutes.
            elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
              echo $(date -Iseconds) INFO: sdn-metrics-certs not mounted. Waiting 20 minutes.
              HAS_LOGGED_INFO=1
            fi
        }

        while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
          log_missing_certs
          sleep 5
        done

        echo $(date -Iseconds) INFO: sdn-metrics-certs mounted, starting kube-rbac-proxy
        exec /usr/bin/kube-rbac-proxy \
          --logtostderr \
          --secure-listen-address=:9101 \
          --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
          --upstream=http://127.0.0.1:29101/ \
          --tls-private-key-file=${TLS_PK} \
          --tls-cert-file=${TLS_CERT}
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9101
        hostPort: 9101
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/tls/metrics-certs
        name: sdn-metrics-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pk9zb
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        set -xe

        touch /var/run/add_iptables.sh
        chmod 0755 /var/run/add_iptables.sh
        cat <<'EOF' > /var/run/add_iptables.sh
        #!/bin/sh
        if [ -z "$3" ]
        then
             echo "Called with host address missing, ignore"
             exit 0
        fi
        echo "Adding ICMP drop rule for '$3' "
        if iptables -C AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        then
             echo "iptables already set for $3"
        else
             iptables -A AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        fi
        EOF

        echo "I$(date "+%m%d %H:%M:%S.%N") - drop-icmp - start drop-icmp ${K8S_NODE}"
        iptables -X AZURE_CHECK_ICMP_SOURCE || true
        iptables -N AZURE_CHECK_ICMP_SOURCE || true
        iptables -F AZURE_CHECK_ICMP_SOURCE
        iptables -D INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE || true
        iptables -I INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE
        iptables -N AZURE_ICMP_ACTION || true
        iptables -F AZURE_ICMP_ACTION
        iptables -A AZURE_ICMP_ACTION -j LOG
        iptables -A AZURE_ICMP_ACTION -j DROP
        /host/usr/bin/oc observe pods -n openshift-sdn -l app=sdn -a '{ .status.hostIP }' -- /var/run/add_iptables.sh
      env:
      - name: K8S_NODE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/bash
            - -c
            - echo drop-icmp done
      name: drop-icmp
      resources:
        requests:
          cpu: 5m
          memory: 20Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        name: host-slash
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pk9zb
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: sdn-dockercfg-46nvg
    nodeName: ocp4azu-sj2sl-worker-noprod-qa-brazilsouth2-rglbf
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: sdn
    serviceAccountName: sdn
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sdn-config
      name: config
    - configMap:
        defaultMode: 420
        name: env-overrides
        optional: true
      name: env-overrides
    - hostPath:
        path: /etc/sysconfig
        type: ""
      name: etc-sysconfig
    - hostPath:
        path: /lib/modules
        type: ""
      name: host-modules
    - hostPath:
        path: /var/run
        type: ""
      name: host-var-run
    - hostPath:
        path: /run/netns
        type: ""
      name: host-run-netns
    - hostPath:
        path: /var/run/netns
        type: ""
      name: host-var-run-netns
    - hostPath:
        path: /var/run/dbus
        type: ""
      name: host-var-run-dbus
    - hostPath:
        path: /var/run/openvswitch
        type: ""
      name: host-var-run-ovs
    - hostPath:
        path: /var/run/kubernetes
        type: ""
      name: host-var-run-kubernetes
    - hostPath:
        path: /var/run/openshift-sdn
        type: ""
      name: host-var-run-openshift-sdn
    - hostPath:
        path: /
        type: ""
      name: host-slash
    - hostPath:
        path: /var/lib/cni/bin
        type: ""
      name: host-cni-bin
    - hostPath:
        path: /var/run/multus/cni/net.d
        type: ""
      name: host-cni-conf
    - hostPath:
        path: /var/lib/cni/networks/openshift-sdn
        type: ""
      name: host-var-lib-cni-networks-openshift-sdn
    - name: sdn-metrics-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: sdn-metrics-certs
    - name: kube-api-access-pk9zb
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T13:31:44Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T13:32:09Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T13:32:09Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T13:31:43Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://39ae5f94c59045b5925bcf8d6d5b2811ffe32fe49c2e5051f81c3b6d8bd06dc5
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: drop-icmp
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T13:32:08Z"
    - containerID: cri-o://c32d0aea5cfa0688e5e77a0498428810e7458c81dace81c0c9bcd8c283a9c19d
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T13:32:08Z"
    - containerID: cri-o://193515535bd755c5328944a7d16dfa76cad3eff0c9dd522b83337ca7f5100e87
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: sdn
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T13:32:03Z"
    hostIP: 10.80.80.22
    phase: Running
    podIP: 10.80.80.22
    podIPs:
    - ip: 10.80.80.22
    qosClass: Burstable
    startTime: "2023-05-25T13:31:44Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-05-04T21:39:44Z"
    generateName: sdn-
    labels:
      app: sdn
      component: network
      controller-revision-hash: 749f49c4cc
      openshift.io/component: network
      pod-template-generation: "1"
      type: infra
    name: sdn-skrc8
    namespace: openshift-sdn
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sdn
      uid: 79c4ac3b-dde1-4470-a005-a221cb9e48d9
    resourceVersion: "1606539"
    uid: eca67221-ac91-4854-8f93-79b505697b4b
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ocp4azu-sj2sl-master-0
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail

        # if another process is listening on the cni-server socket, wait until it exits
        trap 'kill $(jobs -p); rm -f /etc/cni/net.d/80-openshift-network.conf ; exit 0' TERM
        retries=0
        while true; do
          if echo 'test' | socat - UNIX-CONNECT:/var/run/openshift-sdn/cniserver/socket &>/dev/null; then
            echo "warning: Another process is currently listening on the CNI socket, waiting 15s ..." 2>&1
            sleep 15 & wait
            (( retries += 1 ))
          else
            break
          fi
          if [[ "${retries}" -gt 40 ]]; then
            echo "error: Another process is currently listening on the CNI socket, exiting" 2>&1
            exit 1
          fi
        done

        # local environment overrides
        if [[ -f /etc/sysconfig/openshift-sdn ]]; then
          set -o allexport
          source /etc/sysconfig/openshift-sdn
          set +o allexport
        fi
        #BUG: cdc accidentally mounted /etc/sysconfig/openshift-sdn as DirectoryOrCreate; clean it up so we can ultimately mount /etc/sysconfig/openshift-sdn as FileOrCreate
        # Once this is released, then we can mount it properly
        if [[ -d /etc/sysconfig/openshift-sdn ]]; then
          rmdir /etc/sysconfig/openshift-sdn || true
        fi

        # configmap-based overrides
        if [[ -f /env/${K8S_NODE_NAME} ]]; then
          set -o allexport
          source /env/${K8S_NODE_NAME}
          set +o allexport
        fi

        # Take over network functions on the node
        rm -f /etc/cni/net.d/80-openshift-network.conf
        cp -f /opt/cni/bin/openshift-sdn /host-cni-bin/

        mtu_override_flag=
        if [[ -f /config/mtu.yaml ]]; then
          mtu_override_flag="--mtu-override /config/mtu.yaml"
        fi

        # Launch the network process
        exec /usr/bin/openshift-sdn-node \
          --node-name ${K8S_NODE_NAME} --node-ip ${K8S_NODE_IP} \
          --platform-type Azure \
          --proxy-config /config/kube-proxy-config.yaml \
          ${mtu_override_flag} \
          --v ${OPENSHIFT_SDN_LOG_LEVEL:-2}
      env:
      - name: KUBERNETES_SERVICE_PORT
        value: "6443"
      - name: KUBERNETES_SERVICE_HOST
        value: api-int.ocp4azu.dirtrab.cl
      - name: OPENSHIFT_DNS_DOMAIN
        value: cluster.local
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: K8S_NODE_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - rm
            - -f
            - /etc/cni/net.d/80-openshift-network.conf
            - /host-cni-bin/openshift-sdn
      name: sdn
      ports:
      - containerPort: 10256
        hostPort: 10256
        name: healthz
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - test
          - -f
          - /etc/cni/net.d/80-openshift-network.conf
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /config
        name: config
        readOnly: true
      - mountPath: /env
        name: env-overrides
      - mountPath: /var/run
        name: host-var-run
      - mountPath: /var/run/dbus/
        name: host-var-run-dbus
        readOnly: true
      - mountPath: /var/run/openvswitch/
        name: host-var-run-ovs
        readOnly: true
      - mountPath: /var/run/kubernetes/
        name: host-var-run-kubernetes
        readOnly: true
      - mountPath: /run/netns
        mountPropagation: HostToContainer
        name: host-run-netns
        readOnly: true
      - mountPath: /host/var/run/netns
        mountPropagation: HostToContainer
        name: host-var-run-netns
        readOnly: true
      - mountPath: /var/run/openshift-sdn
        name: host-var-run-openshift-sdn
      - mountPath: /host
        mountPropagation: HostToContainer
        name: host-slash
        readOnly: true
      - mountPath: /host-cni-bin
        name: host-cni-bin
      - mountPath: /etc/cni/net.d
        name: host-cni-conf
      - mountPath: /var/lib/cni/networks/openshift-sdn
        name: host-var-lib-cni-networks-openshift-sdn
      - mountPath: /lib/modules
        name: host-modules
        readOnly: true
      - mountPath: /etc/sysconfig
        name: etc-sysconfig
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-98ssb
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail
        TLS_PK=/etc/pki/tls/metrics-certs/tls.key
        TLS_CERT=/etc/pki/tls/metrics-certs/tls.crt

        # As the secret mount is optional we must wait for the files to be present.
        # The service is created in monitor.yaml and this is created in sdn.yaml.
        # If it isn't created there is probably an issue so we want to crashloop.
        TS=$(date +%s)
        WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
        HAS_LOGGED_INFO=0

        log_missing_certs(){
            CUR_TS=$(date +%s)
            if [[ "${CUR_TS}" -gt "WARN_TS"  ]]; then
              echo $(date -Iseconds) WARN: sdn-metrics-certs not mounted after 20 minutes.
            elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
              echo $(date -Iseconds) INFO: sdn-metrics-certs not mounted. Waiting 20 minutes.
              HAS_LOGGED_INFO=1
            fi
        }

        while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
          log_missing_certs
          sleep 5
        done

        echo $(date -Iseconds) INFO: sdn-metrics-certs mounted, starting kube-rbac-proxy
        exec /usr/bin/kube-rbac-proxy \
          --logtostderr \
          --secure-listen-address=:9101 \
          --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
          --upstream=http://127.0.0.1:29101/ \
          --tls-private-key-file=${TLS_PK} \
          --tls-cert-file=${TLS_CERT}
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9101
        hostPort: 9101
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/tls/metrics-certs
        name: sdn-metrics-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-98ssb
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        set -xe

        touch /var/run/add_iptables.sh
        chmod 0755 /var/run/add_iptables.sh
        cat <<'EOF' > /var/run/add_iptables.sh
        #!/bin/sh
        if [ -z "$3" ]
        then
             echo "Called with host address missing, ignore"
             exit 0
        fi
        echo "Adding ICMP drop rule for '$3' "
        if iptables -C AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        then
             echo "iptables already set for $3"
        else
             iptables -A AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        fi
        EOF

        echo "I$(date "+%m%d %H:%M:%S.%N") - drop-icmp - start drop-icmp ${K8S_NODE}"
        iptables -X AZURE_CHECK_ICMP_SOURCE || true
        iptables -N AZURE_CHECK_ICMP_SOURCE || true
        iptables -F AZURE_CHECK_ICMP_SOURCE
        iptables -D INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE || true
        iptables -I INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE
        iptables -N AZURE_ICMP_ACTION || true
        iptables -F AZURE_ICMP_ACTION
        iptables -A AZURE_ICMP_ACTION -j LOG
        iptables -A AZURE_ICMP_ACTION -j DROP
        /host/usr/bin/oc observe pods -n openshift-sdn -l app=sdn -a '{ .status.hostIP }' -- /var/run/add_iptables.sh
      env:
      - name: K8S_NODE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/bash
            - -c
            - echo drop-icmp done
      name: drop-icmp
      resources:
        requests:
          cpu: 5m
          memory: 20Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        name: host-slash
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-98ssb
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    nodeName: ocp4azu-sj2sl-master-0
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: sdn
    serviceAccountName: sdn
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sdn-config
      name: config
    - configMap:
        defaultMode: 420
        name: env-overrides
        optional: true
      name: env-overrides
    - hostPath:
        path: /etc/sysconfig
        type: ""
      name: etc-sysconfig
    - hostPath:
        path: /lib/modules
        type: ""
      name: host-modules
    - hostPath:
        path: /var/run
        type: ""
      name: host-var-run
    - hostPath:
        path: /run/netns
        type: ""
      name: host-run-netns
    - hostPath:
        path: /var/run/netns
        type: ""
      name: host-var-run-netns
    - hostPath:
        path: /var/run/dbus
        type: ""
      name: host-var-run-dbus
    - hostPath:
        path: /var/run/openvswitch
        type: ""
      name: host-var-run-ovs
    - hostPath:
        path: /var/run/kubernetes
        type: ""
      name: host-var-run-kubernetes
    - hostPath:
        path: /var/run/openshift-sdn
        type: ""
      name: host-var-run-openshift-sdn
    - hostPath:
        path: /
        type: ""
      name: host-slash
    - hostPath:
        path: /var/lib/cni/bin
        type: ""
      name: host-cni-bin
    - hostPath:
        path: /var/run/multus/cni/net.d
        type: ""
      name: host-cni-conf
    - hostPath:
        path: /var/lib/cni/networks/openshift-sdn
        type: ""
      name: host-var-lib-cni-networks-openshift-sdn
    - name: sdn-metrics-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: sdn-metrics-certs
    - name: kube-api-access-98ssb
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-05-04T21:39:44Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-05-11T18:26:26Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-05-11T18:26:26Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-05-04T21:39:44Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://e4279be551dc9c20f210e63ab9773d1c3310dbb13c215ddec18c64749f35a657
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: drop-icmp
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2023-05-11T18:26:13Z"
    - containerID: cri-o://fa7b751f6f22d9431d3de502f899fec55d576d83d4f421567671ae6539301da1
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2023-05-11T18:26:13Z"
    - containerID: cri-o://7430c0b8d75182860adb0b82784423b612de2b970bda6af4601b2b29f7cc0bcf
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: sdn
      ready: true
      restartCount: 3
      started: true
      state:
        running:
          startedAt: "2023-05-11T18:26:13Z"
    hostIP: 10.80.80.6
    phase: Running
    podIP: 10.80.80.6
    podIPs:
    - ip: 10.80.80.6
    qosClass: Burstable
    startTime: "2023-05-04T21:39:44Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-06-05T02:11:56Z"
    generateName: sdn-
    labels:
      app: sdn
      component: network
      controller-revision-hash: 749f49c4cc
      openshift.io/component: network
      pod-template-generation: "1"
      type: infra
    name: sdn-t8qrx
    namespace: openshift-sdn
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sdn
      uid: 79c4ac3b-dde1-4470-a005-a221cb9e48d9
    resourceVersion: "466147475"
    uid: 3a7646dc-81ae-4b6c-9a29-0cc62a19bf67
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ocp4azu-sj2sl-worker-prod-brazilsouth3-vmmxw
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail

        # if another process is listening on the cni-server socket, wait until it exits
        trap 'kill $(jobs -p); rm -f /etc/cni/net.d/80-openshift-network.conf ; exit 0' TERM
        retries=0
        while true; do
          if echo 'test' | socat - UNIX-CONNECT:/var/run/openshift-sdn/cniserver/socket &>/dev/null; then
            echo "warning: Another process is currently listening on the CNI socket, waiting 15s ..." 2>&1
            sleep 15 & wait
            (( retries += 1 ))
          else
            break
          fi
          if [[ "${retries}" -gt 40 ]]; then
            echo "error: Another process is currently listening on the CNI socket, exiting" 2>&1
            exit 1
          fi
        done

        # local environment overrides
        if [[ -f /etc/sysconfig/openshift-sdn ]]; then
          set -o allexport
          source /etc/sysconfig/openshift-sdn
          set +o allexport
        fi
        #BUG: cdc accidentally mounted /etc/sysconfig/openshift-sdn as DirectoryOrCreate; clean it up so we can ultimately mount /etc/sysconfig/openshift-sdn as FileOrCreate
        # Once this is released, then we can mount it properly
        if [[ -d /etc/sysconfig/openshift-sdn ]]; then
          rmdir /etc/sysconfig/openshift-sdn || true
        fi

        # configmap-based overrides
        if [[ -f /env/${K8S_NODE_NAME} ]]; then
          set -o allexport
          source /env/${K8S_NODE_NAME}
          set +o allexport
        fi

        # Take over network functions on the node
        rm -f /etc/cni/net.d/80-openshift-network.conf
        cp -f /opt/cni/bin/openshift-sdn /host-cni-bin/

        mtu_override_flag=
        if [[ -f /config/mtu.yaml ]]; then
          mtu_override_flag="--mtu-override /config/mtu.yaml"
        fi

        # Launch the network process
        exec /usr/bin/openshift-sdn-node \
          --node-name ${K8S_NODE_NAME} --node-ip ${K8S_NODE_IP} \
          --platform-type Azure \
          --proxy-config /config/kube-proxy-config.yaml \
          ${mtu_override_flag} \
          --v ${OPENSHIFT_SDN_LOG_LEVEL:-2}
      env:
      - name: KUBERNETES_SERVICE_PORT
        value: "6443"
      - name: KUBERNETES_SERVICE_HOST
        value: api-int.ocp4azu.dirtrab.cl
      - name: OPENSHIFT_DNS_DOMAIN
        value: cluster.local
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: K8S_NODE_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - rm
            - -f
            - /etc/cni/net.d/80-openshift-network.conf
            - /host-cni-bin/openshift-sdn
      name: sdn
      ports:
      - containerPort: 10256
        hostPort: 10256
        name: healthz
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - test
          - -f
          - /etc/cni/net.d/80-openshift-network.conf
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /config
        name: config
        readOnly: true
      - mountPath: /env
        name: env-overrides
      - mountPath: /var/run
        name: host-var-run
      - mountPath: /var/run/dbus/
        name: host-var-run-dbus
        readOnly: true
      - mountPath: /var/run/openvswitch/
        name: host-var-run-ovs
        readOnly: true
      - mountPath: /var/run/kubernetes/
        name: host-var-run-kubernetes
        readOnly: true
      - mountPath: /run/netns
        mountPropagation: HostToContainer
        name: host-run-netns
        readOnly: true
      - mountPath: /host/var/run/netns
        mountPropagation: HostToContainer
        name: host-var-run-netns
        readOnly: true
      - mountPath: /var/run/openshift-sdn
        name: host-var-run-openshift-sdn
      - mountPath: /host
        mountPropagation: HostToContainer
        name: host-slash
        readOnly: true
      - mountPath: /host-cni-bin
        name: host-cni-bin
      - mountPath: /etc/cni/net.d
        name: host-cni-conf
      - mountPath: /var/lib/cni/networks/openshift-sdn
        name: host-var-lib-cni-networks-openshift-sdn
      - mountPath: /lib/modules
        name: host-modules
        readOnly: true
      - mountPath: /etc/sysconfig
        name: etc-sysconfig
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zx9l6
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail
        TLS_PK=/etc/pki/tls/metrics-certs/tls.key
        TLS_CERT=/etc/pki/tls/metrics-certs/tls.crt

        # As the secret mount is optional we must wait for the files to be present.
        # The service is created in monitor.yaml and this is created in sdn.yaml.
        # If it isn't created there is probably an issue so we want to crashloop.
        TS=$(date +%s)
        WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
        HAS_LOGGED_INFO=0

        log_missing_certs(){
            CUR_TS=$(date +%s)
            if [[ "${CUR_TS}" -gt "WARN_TS"  ]]; then
              echo $(date -Iseconds) WARN: sdn-metrics-certs not mounted after 20 minutes.
            elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
              echo $(date -Iseconds) INFO: sdn-metrics-certs not mounted. Waiting 20 minutes.
              HAS_LOGGED_INFO=1
            fi
        }

        while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
          log_missing_certs
          sleep 5
        done

        echo $(date -Iseconds) INFO: sdn-metrics-certs mounted, starting kube-rbac-proxy
        exec /usr/bin/kube-rbac-proxy \
          --logtostderr \
          --secure-listen-address=:9101 \
          --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
          --upstream=http://127.0.0.1:29101/ \
          --tls-private-key-file=${TLS_PK} \
          --tls-cert-file=${TLS_CERT}
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9101
        hostPort: 9101
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/tls/metrics-certs
        name: sdn-metrics-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zx9l6
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        set -xe

        touch /var/run/add_iptables.sh
        chmod 0755 /var/run/add_iptables.sh
        cat <<'EOF' > /var/run/add_iptables.sh
        #!/bin/sh
        if [ -z "$3" ]
        then
             echo "Called with host address missing, ignore"
             exit 0
        fi
        echo "Adding ICMP drop rule for '$3' "
        if iptables -C AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        then
             echo "iptables already set for $3"
        else
             iptables -A AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        fi
        EOF

        echo "I$(date "+%m%d %H:%M:%S.%N") - drop-icmp - start drop-icmp ${K8S_NODE}"
        iptables -X AZURE_CHECK_ICMP_SOURCE || true
        iptables -N AZURE_CHECK_ICMP_SOURCE || true
        iptables -F AZURE_CHECK_ICMP_SOURCE
        iptables -D INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE || true
        iptables -I INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE
        iptables -N AZURE_ICMP_ACTION || true
        iptables -F AZURE_ICMP_ACTION
        iptables -A AZURE_ICMP_ACTION -j LOG
        iptables -A AZURE_ICMP_ACTION -j DROP
        /host/usr/bin/oc observe pods -n openshift-sdn -l app=sdn -a '{ .status.hostIP }' -- /var/run/add_iptables.sh
      env:
      - name: K8S_NODE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/bash
            - -c
            - echo drop-icmp done
      name: drop-icmp
      resources:
        requests:
          cpu: 5m
          memory: 20Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        name: host-slash
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-zx9l6
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: sdn-dockercfg-46nvg
    nodeName: ocp4azu-sj2sl-worker-prod-brazilsouth3-vmmxw
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: sdn
    serviceAccountName: sdn
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sdn-config
      name: config
    - configMap:
        defaultMode: 420
        name: env-overrides
        optional: true
      name: env-overrides
    - hostPath:
        path: /etc/sysconfig
        type: ""
      name: etc-sysconfig
    - hostPath:
        path: /lib/modules
        type: ""
      name: host-modules
    - hostPath:
        path: /var/run
        type: ""
      name: host-var-run
    - hostPath:
        path: /run/netns
        type: ""
      name: host-run-netns
    - hostPath:
        path: /var/run/netns
        type: ""
      name: host-var-run-netns
    - hostPath:
        path: /var/run/dbus
        type: ""
      name: host-var-run-dbus
    - hostPath:
        path: /var/run/openvswitch
        type: ""
      name: host-var-run-ovs
    - hostPath:
        path: /var/run/kubernetes
        type: ""
      name: host-var-run-kubernetes
    - hostPath:
        path: /var/run/openshift-sdn
        type: ""
      name: host-var-run-openshift-sdn
    - hostPath:
        path: /
        type: ""
      name: host-slash
    - hostPath:
        path: /var/lib/cni/bin
        type: ""
      name: host-cni-bin
    - hostPath:
        path: /var/run/multus/cni/net.d
        type: ""
      name: host-cni-conf
    - hostPath:
        path: /var/lib/cni/networks/openshift-sdn
        type: ""
      name: host-var-lib-cni-networks-openshift-sdn
    - name: sdn-metrics-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: sdn-metrics-certs
    - name: kube-api-access-zx9l6
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-06-05T02:11:57Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-01-17T22:41:08Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-01-17T22:41:08Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-06-05T02:11:56Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://19413cdb2649972e44e8cf3a05bd8df1d3f0dd17ddb2c8fbec073e6c217794af
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: drop-icmp
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-01-17T22:41:06Z"
    - containerID: cri-o://6d73872ae8a0d1eebedec7844b538a03ddd3a6e3d73a645c27afc18c238cd080
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-01-17T22:40:59Z"
    - containerID: cri-o://17147c3d19753778e3f30e29cd7553cd714cb36409b1897d0a89835edef085cc
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: sdn
      ready: true
      restartCount: 1
      started: true
      state:
        running:
          startedAt: "2024-01-17T22:38:50Z"
    hostIP: 10.80.80.18
    phase: Running
    podIP: 10.80.80.18
    podIPs:
    - ip: 10.80.80.18
    qosClass: Burstable
    startTime: "2023-06-05T02:11:57Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2023-05-25T13:39:12Z"
    generateName: sdn-
    labels:
      app: sdn
      component: network
      controller-revision-hash: 749f49c4cc
      openshift.io/component: network
      pod-template-generation: "1"
      type: infra
    name: sdn-zqr6t
    namespace: openshift-sdn
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: sdn
      uid: 79c4ac3b-dde1-4470-a005-a221cb9e48d9
    resourceVersion: "472847182"
    uid: a0068cc3-8558-48f9-83af-321af103985d
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ocp4azu-sj2sl-worker-prod-brazilsouth2-xbz5z
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail

        # if another process is listening on the cni-server socket, wait until it exits
        trap 'kill $(jobs -p); rm -f /etc/cni/net.d/80-openshift-network.conf ; exit 0' TERM
        retries=0
        while true; do
          if echo 'test' | socat - UNIX-CONNECT:/var/run/openshift-sdn/cniserver/socket &>/dev/null; then
            echo "warning: Another process is currently listening on the CNI socket, waiting 15s ..." 2>&1
            sleep 15 & wait
            (( retries += 1 ))
          else
            break
          fi
          if [[ "${retries}" -gt 40 ]]; then
            echo "error: Another process is currently listening on the CNI socket, exiting" 2>&1
            exit 1
          fi
        done

        # local environment overrides
        if [[ -f /etc/sysconfig/openshift-sdn ]]; then
          set -o allexport
          source /etc/sysconfig/openshift-sdn
          set +o allexport
        fi
        #BUG: cdc accidentally mounted /etc/sysconfig/openshift-sdn as DirectoryOrCreate; clean it up so we can ultimately mount /etc/sysconfig/openshift-sdn as FileOrCreate
        # Once this is released, then we can mount it properly
        if [[ -d /etc/sysconfig/openshift-sdn ]]; then
          rmdir /etc/sysconfig/openshift-sdn || true
        fi

        # configmap-based overrides
        if [[ -f /env/${K8S_NODE_NAME} ]]; then
          set -o allexport
          source /env/${K8S_NODE_NAME}
          set +o allexport
        fi

        # Take over network functions on the node
        rm -f /etc/cni/net.d/80-openshift-network.conf
        cp -f /opt/cni/bin/openshift-sdn /host-cni-bin/

        mtu_override_flag=
        if [[ -f /config/mtu.yaml ]]; then
          mtu_override_flag="--mtu-override /config/mtu.yaml"
        fi

        # Launch the network process
        exec /usr/bin/openshift-sdn-node \
          --node-name ${K8S_NODE_NAME} --node-ip ${K8S_NODE_IP} \
          --platform-type Azure \
          --proxy-config /config/kube-proxy-config.yaml \
          ${mtu_override_flag} \
          --v ${OPENSHIFT_SDN_LOG_LEVEL:-2}
      env:
      - name: KUBERNETES_SERVICE_PORT
        value: "6443"
      - name: KUBERNETES_SERVICE_HOST
        value: api-int.ocp4azu.dirtrab.cl
      - name: OPENSHIFT_DNS_DOMAIN
        value: cluster.local
      - name: K8S_NODE_NAME
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      - name: K8S_NODE_IP
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: status.hostIP
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - rm
            - -f
            - /etc/cni/net.d/80-openshift-network.conf
            - /host-cni-bin/openshift-sdn
      name: sdn
      ports:
      - containerPort: 10256
        hostPort: 10256
        name: healthz
        protocol: TCP
      readinessProbe:
        exec:
          command:
          - test
          - -f
          - /etc/cni/net.d/80-openshift-network.conf
        failureThreshold: 3
        initialDelaySeconds: 5
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 1
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /config
        name: config
        readOnly: true
      - mountPath: /env
        name: env-overrides
      - mountPath: /var/run
        name: host-var-run
      - mountPath: /var/run/dbus/
        name: host-var-run-dbus
        readOnly: true
      - mountPath: /var/run/openvswitch/
        name: host-var-run-ovs
        readOnly: true
      - mountPath: /var/run/kubernetes/
        name: host-var-run-kubernetes
        readOnly: true
      - mountPath: /run/netns
        mountPropagation: HostToContainer
        name: host-run-netns
        readOnly: true
      - mountPath: /host/var/run/netns
        mountPropagation: HostToContainer
        name: host-var-run-netns
        readOnly: true
      - mountPath: /var/run/openshift-sdn
        name: host-var-run-openshift-sdn
      - mountPath: /host
        mountPropagation: HostToContainer
        name: host-slash
        readOnly: true
      - mountPath: /host-cni-bin
        name: host-cni-bin
      - mountPath: /etc/cni/net.d
        name: host-cni-conf
      - mountPath: /var/lib/cni/networks/openshift-sdn
        name: host-var-lib-cni-networks-openshift-sdn
      - mountPath: /lib/modules
        name: host-modules
        readOnly: true
      - mountPath: /etc/sysconfig
        name: etc-sysconfig
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-fjlp9
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -euo pipefail
        TLS_PK=/etc/pki/tls/metrics-certs/tls.key
        TLS_CERT=/etc/pki/tls/metrics-certs/tls.crt

        # As the secret mount is optional we must wait for the files to be present.
        # The service is created in monitor.yaml and this is created in sdn.yaml.
        # If it isn't created there is probably an issue so we want to crashloop.
        TS=$(date +%s)
        WARN_TS=$(( ${TS} + $(( 20 * 60)) ))
        HAS_LOGGED_INFO=0

        log_missing_certs(){
            CUR_TS=$(date +%s)
            if [[ "${CUR_TS}" -gt "WARN_TS"  ]]; then
              echo $(date -Iseconds) WARN: sdn-metrics-certs not mounted after 20 minutes.
            elif [[ "${HAS_LOGGED_INFO}" -eq 0 ]] ; then
              echo $(date -Iseconds) INFO: sdn-metrics-certs not mounted. Waiting 20 minutes.
              HAS_LOGGED_INFO=1
            fi
        }

        while [[ ! -f "${TLS_PK}" ||  ! -f "${TLS_CERT}" ]] ; do
          log_missing_certs
          sleep 5
        done

        echo $(date -Iseconds) INFO: sdn-metrics-certs mounted, starting kube-rbac-proxy
        exec /usr/bin/kube-rbac-proxy \
          --logtostderr \
          --secure-listen-address=:9101 \
          --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 \
          --upstream=http://127.0.0.1:29101/ \
          --tls-private-key-file=${TLS_PK} \
          --tls-cert-file=${TLS_CERT}
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9101
        hostPort: 9101
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/pki/tls/metrics-certs
        name: sdn-metrics-certs
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-fjlp9
        readOnly: true
    - command:
      - /bin/bash
      - -c
      - |
        set -xe

        touch /var/run/add_iptables.sh
        chmod 0755 /var/run/add_iptables.sh
        cat <<'EOF' > /var/run/add_iptables.sh
        #!/bin/sh
        if [ -z "$3" ]
        then
             echo "Called with host address missing, ignore"
             exit 0
        fi
        echo "Adding ICMP drop rule for '$3' "
        if iptables -C AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        then
             echo "iptables already set for $3"
        else
             iptables -A AZURE_CHECK_ICMP_SOURCE -p icmp -s $3 -j AZURE_ICMP_ACTION
        fi
        EOF

        echo "I$(date "+%m%d %H:%M:%S.%N") - drop-icmp - start drop-icmp ${K8S_NODE}"
        iptables -X AZURE_CHECK_ICMP_SOURCE || true
        iptables -N AZURE_CHECK_ICMP_SOURCE || true
        iptables -F AZURE_CHECK_ICMP_SOURCE
        iptables -D INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE || true
        iptables -I INPUT -p icmp --icmp-type fragmentation-needed -j AZURE_CHECK_ICMP_SOURCE
        iptables -N AZURE_ICMP_ACTION || true
        iptables -F AZURE_ICMP_ACTION
        iptables -A AZURE_ICMP_ACTION -j LOG
        iptables -A AZURE_ICMP_ACTION -j DROP
        /host/usr/bin/oc observe pods -n openshift-sdn -l app=sdn -a '{ .status.hostIP }' -- /var/run/add_iptables.sh
      env:
      - name: K8S_NODE
        valueFrom:
          fieldRef:
            apiVersion: v1
            fieldPath: spec.nodeName
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imagePullPolicy: IfNotPresent
      lifecycle:
        preStop:
          exec:
            command:
            - /bin/bash
            - -c
            - echo drop-icmp done
      name: drop-icmp
      resources:
        requests:
          cpu: 5m
          memory: 20Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /host
        name: host-slash
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-fjlp9
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    hostPID: true
    imagePullSecrets:
    - name: sdn-dockercfg-46nvg
    nodeName: ocp4azu-sj2sl-worker-prod-brazilsouth2-xbz5z
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: sdn
    serviceAccountName: sdn
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: sdn-config
      name: config
    - configMap:
        defaultMode: 420
        name: env-overrides
        optional: true
      name: env-overrides
    - hostPath:
        path: /etc/sysconfig
        type: ""
      name: etc-sysconfig
    - hostPath:
        path: /lib/modules
        type: ""
      name: host-modules
    - hostPath:
        path: /var/run
        type: ""
      name: host-var-run
    - hostPath:
        path: /run/netns
        type: ""
      name: host-run-netns
    - hostPath:
        path: /var/run/netns
        type: ""
      name: host-var-run-netns
    - hostPath:
        path: /var/run/dbus
        type: ""
      name: host-var-run-dbus
    - hostPath:
        path: /var/run/openvswitch
        type: ""
      name: host-var-run-ovs
    - hostPath:
        path: /var/run/kubernetes
        type: ""
      name: host-var-run-kubernetes
    - hostPath:
        path: /var/run/openshift-sdn
        type: ""
      name: host-var-run-openshift-sdn
    - hostPath:
        path: /
        type: ""
      name: host-slash
    - hostPath:
        path: /var/lib/cni/bin
        type: ""
      name: host-cni-bin
    - hostPath:
        path: /var/run/multus/cni/net.d
        type: ""
      name: host-cni-conf
    - hostPath:
        path: /var/lib/cni/networks/openshift-sdn
        type: ""
      name: host-var-lib-cni-networks-openshift-sdn
    - name: sdn-metrics-certs
      secret:
        defaultMode: 420
        optional: true
        secretName: sdn-metrics-certs
    - name: kube-api-access-fjlp9
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T13:39:12Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T13:39:36Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T13:39:36Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2023-05-25T13:39:12Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://c8361534b9f3a976617245ed7066bf15da4e75ce744782e388d16ca75b8083d5
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: drop-icmp
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T13:39:36Z"
    - containerID: cri-o://28a7a069b0ca5218b1c86497dd9eef95d2b567ab591289721179c969b46a1676
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:d253bc69fdc967c1fc1543b01deddacd4eefe816cc9ed4541ea3673e35321753
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T13:39:35Z"
    - containerID: cri-o://7d4f789c705e779216983cad26ca9c410447bcf51d2fe8345e93a836957b6948
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:8e8b4b5ac67750dd7c0dc9d83a7ddae6db4cceb6ad2989738fe4b1a2f4a72445
      lastState: {}
      name: sdn
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2023-05-25T13:39:30Z"
    hostIP: 10.80.80.23
    phase: Running
    podIP: 10.80.80.23
    podIPs:
    - ip: 10.80.80.23
    qosClass: Burstable
    startTime: "2023-05-25T13:39:12Z"
kind: List
metadata:
  resourceVersion: ""
  selfLink: ""
